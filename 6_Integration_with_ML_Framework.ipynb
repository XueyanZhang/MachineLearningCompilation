{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyN4biOrX1xgCW16yndTwh5g",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/XueyanZhang/MachineLearningCompilation/blob/master/6_Integration_with_ML_Framework.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eM_tP5o9eg24"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Integration with Machine Learning Frameworks"
      ],
      "metadata": {
        "id": "zrSj4-I1eq_M"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!python3 -m  pip install mlc-ai-nightly -f https://mlc.ai/wheels\n",
        "\n",
        "import numpy as np\n",
        "import tvm\n",
        "from tvm import relax\n",
        "from tvm.ir.module import IRModule\n",
        "from tvm.script import relax as R\n",
        "from tvm.script import tir as T\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch import fx\n",
        "from torch.nn import functional as F"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CFoZkvdkesQ-",
        "outputId": "434477d2-e0c0-40b3-f516-47850b2799b4"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Looking in links: https://mlc.ai/wheels\n",
            "Collecting mlc-ai-nightly\n",
            "  Downloading https://github.com/mlc-ai/utils/releases/download/v0.9.dev0/mlc_ai_nightly-0.12.dev929%2Bgc0e455773-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (52.2 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m52.2/52.2 MB\u001b[0m \u001b[31m13.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: attrs in /usr/local/lib/python3.10/dist-packages (from mlc-ai-nightly) (23.1.0)\n",
            "Requirement already satisfied: cloudpickle in /usr/local/lib/python3.10/dist-packages (from mlc-ai-nightly) (2.2.1)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.10/dist-packages (from mlc-ai-nightly) (4.4.2)\n",
            "Requirement already satisfied: numpy<=1.23 in /usr/local/lib/python3.10/dist-packages (from mlc-ai-nightly) (1.22.4)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from mlc-ai-nightly) (5.9.5)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from mlc-ai-nightly) (1.10.1)\n",
            "Requirement already satisfied: tornado in /usr/local/lib/python3.10/dist-packages (from mlc-ai-nightly) (6.3.1)\n",
            "Installing collected packages: mlc-ai-nightly\n",
            "Successfully installed mlc-ai-nightly-0.12.dev929+gc0e455773\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Build IRModule via Builder\n",
        "\n",
        "past IRModules was written mannual in TVMScript.\n",
        "\n",
        "it doesn't meet the demand for large systems.\n",
        "\n",
        "need a way to construct IRModule programmatically."
      ],
      "metadata": {
        "id": "B4VnhVBee6RV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Tensor Expression\n",
        "\n",
        "Tensor Expression for TensorIR Creation"
      ],
      "metadata": {
        "id": "kC80RTWWfXW7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tvm import te\n",
        "\n",
        "# create input\n",
        "f32 = \"float32\"\n",
        "A = te.placeholder((128, 128), name=\"A\", dtype=\"float32\")\n",
        "B = te.placeholder((128, 128), name=\"B\", dtype=\"float32\")\n",
        "print(type(A))\n",
        "print(A.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "am8PqFpaeyku",
        "outputId": "4cb41b41-b570-41dd-b2a4-92bf8d5cec3f"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'tvm.te.tensor.Tensor'>\n",
            "[128, 128]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# define computation\n",
        "def te_matmul(A: te.Tensor, B: te.Tensor) -> te.Tensor:\n",
        "    assert A.shape[1] == B.shape[0]\n",
        "    m = A.shape[0]\n",
        "    n = B.shape[1]\n",
        "    k = te.reduce_axis((0, A.shape[1]), name='k')\n",
        "    return te.compute((m, n), lambda i, j: te.sum(A[i, k] * B[k, j], axis=k), name=\"matmul\")"
      ],
      "metadata": {
        "id": "KCyRaJ8Df2D_"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# create result\n",
        "C = te_matmul(A, B)\n",
        "print(C)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EI3j9AZBg8Jv",
        "outputId": "b9cafd39-28aa-4c05-f485-68a8819aa711"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tensor(shape=[128, 128], op.name=matmul)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# create TensorIR function\n",
        "te.create_prim_func([A, B, C]).show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 331
        },
        "id": "zG_a1NNfhRRe",
        "outputId": "421d7a19-bddf-4897-8975-6e827ee6ec62"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/tvm/script/highlight.py:117: UserWarning: No module named 'black'\n",
            "To print formatted TVM script, please install the formatter 'Black':\n",
            "/usr/bin/python3 -m pip install \"black==22.3.0\" --upgrade --user\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<div class=\"highlight\" style=\"background: \"><pre style=\"line-height: 125%;\"><span></span><span style=\"color: #007979; font-style: italic\"># from tvm.script import tir as T</span>\n",
              "\n",
              "<span style=\"color: #AA22FF\">@T</span><span style=\"color: #AA22FF; font-weight: bold\">.</span>prim_func\n",
              "<span style=\"color: #008000; font-weight: bold\">def</span> <span style=\"color: #0000FF\">main</span>(A: T<span style=\"color: #AA22FF; font-weight: bold\">.</span>Buffer((<span style=\"color: #008000\">128</span>, <span style=\"color: #008000\">128</span>), <span style=\"color: #BA2121\">&quot;float32&quot;</span>), B: T<span style=\"color: #AA22FF; font-weight: bold\">.</span>Buffer((<span style=\"color: #008000\">128</span>, <span style=\"color: #008000\">128</span>), <span style=\"color: #BA2121\">&quot;float32&quot;</span>), matmul: T<span style=\"color: #AA22FF; font-weight: bold\">.</span>Buffer((<span style=\"color: #008000\">128</span>, <span style=\"color: #008000\">128</span>), <span style=\"color: #BA2121\">&quot;float32&quot;</span>)):\n",
              "    T<span style=\"color: #AA22FF; font-weight: bold\">.</span>func_attr({<span style=\"color: #BA2121\">&quot;global_symbol&quot;</span>: <span style=\"color: #BA2121\">&quot;main&quot;</span>, <span style=\"color: #BA2121\">&quot;tir.noalias&quot;</span>: T<span style=\"color: #AA22FF; font-weight: bold\">.</span>bool(<span style=\"color: #008000; font-weight: bold\">True</span>)})\n",
              "    <span style=\"color: #007979; font-style: italic\"># with T.block(&quot;root&quot;):</span>\n",
              "    <span style=\"color: #008000; font-weight: bold\">for</span> i, j, k <span style=\"color: #008000; font-weight: bold\">in</span> T<span style=\"color: #AA22FF; font-weight: bold\">.</span>grid(<span style=\"color: #008000\">128</span>, <span style=\"color: #008000\">128</span>, <span style=\"color: #008000\">128</span>):\n",
              "        <span style=\"color: #008000; font-weight: bold\">with</span> T<span style=\"color: #AA22FF; font-weight: bold\">.</span>block(<span style=\"color: #BA2121\">&quot;matmul&quot;</span>):\n",
              "            v_i, v_j, v_k <span style=\"color: #AA22FF; font-weight: bold\">=</span> T<span style=\"color: #AA22FF; font-weight: bold\">.</span>axis<span style=\"color: #AA22FF; font-weight: bold\">.</span>remap(<span style=\"color: #BA2121\">&quot;SSR&quot;</span>, [i, j, k])\n",
              "            T<span style=\"color: #AA22FF; font-weight: bold\">.</span>reads(A[v_i, v_k], B[v_k, v_j])\n",
              "            T<span style=\"color: #AA22FF; font-weight: bold\">.</span>writes(matmul[v_i, v_j])\n",
              "            <span style=\"color: #008000; font-weight: bold\">with</span> T<span style=\"color: #AA22FF; font-weight: bold\">.</span>init():\n",
              "                matmul[v_i, v_j] <span style=\"color: #AA22FF; font-weight: bold\">=</span> T<span style=\"color: #AA22FF; font-weight: bold\">.</span>float32(<span style=\"color: #008000\">0</span>)\n",
              "            matmul[v_i, v_j] <span style=\"color: #AA22FF; font-weight: bold\">=</span> matmul[v_i, v_j] <span style=\"color: #AA22FF; font-weight: bold\">+</span> A[v_i, v_k] <span style=\"color: #AA22FF; font-weight: bold\">*</span> B[v_k, v_j]\n",
              "</pre></div>\n"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# create relu func\n",
        "def te_relu(A: te.Tensor) -> te.Tensor:\n",
        "    return te.compute(A.shape, lambda *i: te.max(A(*i), 0), name=\"relu\")"
      ],
      "metadata": {
        "id": "Td_nmPULhph2"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "the `*i` represents arbitrary shape index. here are some examples:"
      ],
      "metadata": {
        "id": "qvAPFBYciREl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 1D input\n",
        "X1 = te.placeholder((10, ), dtype=f32, name='X1')\n",
        "Y1 = te_relu(X1)\n",
        "te.create_prim_func([X1, Y1])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HqHklnzYiO6v",
        "outputId": "f3727dca-5b75-457e-9079-83666959ac31"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "# from tvm.script import tir as T\n",
              "\n",
              "@T.prim_func\n",
              "def main(X1: T.Buffer((10,), \"float32\"), relu: T.Buffer((10,), \"float32\")):\n",
              "    T.func_attr({\"global_symbol\": \"main\", \"tir.noalias\": T.bool(True)})\n",
              "    # with T.block(\"root\"):\n",
              "    for i0 in range(10):\n",
              "        with T.block(\"relu\"):\n",
              "            v_i0 = T.axis.spatial(10, i0)\n",
              "            T.reads(X1[v_i0])\n",
              "            T.writes(relu[v_i0])\n",
              "            relu[v_i0] = T.max(X1[v_i0], T.float32(0))"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 2D input\n",
        "X2 = te.placeholder((10, 10), dtype=f32, name='X2')\n",
        "Y2 = te_relu(X2)\n",
        "te.create_prim_func([X2, Y2])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2KTtfnt3irR9",
        "outputId": "7f4665f8-f454-41d6-d526-615c31b1e63a"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "# from tvm.script import tir as T\n",
              "\n",
              "@T.prim_func\n",
              "def main(X2: T.Buffer((10, 10), \"float32\"), relu: T.Buffer((10, 10), \"float32\")):\n",
              "    T.func_attr({\"global_symbol\": \"main\", \"tir.noalias\": T.bool(True)})\n",
              "    # with T.block(\"root\"):\n",
              "    for i0, i1 in T.grid(10, 10):\n",
              "        with T.block(\"relu\"):\n",
              "            v_i0, v_i1 = T.axis.remap(\"SS\", [i0, i1])\n",
              "            T.reads(X2[v_i0, v_i1])\n",
              "            T.writes(relu[v_i0, v_i1])\n",
              "            relu[v_i0, v_i1] = T.max(X2[v_i0, v_i1], T.float32(0))"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## fuse / fusion "
      ],
      "metadata": {
        "id": "34ozR2-Li5rq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# fuse matmul w/ relu\n",
        "C = te_matmul(A, B)\n",
        "D = te_relu(C)\n",
        "\n",
        "te.create_prim_func([A, B, D]).show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 454
        },
        "id": "MazeFDKJjA9G",
        "outputId": "a0e54e8e-b3dd-4ccc-baf7-5d0f9649534c"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/tvm/script/highlight.py:117: UserWarning: No module named 'black'\n",
            "To print formatted TVM script, please install the formatter 'Black':\n",
            "/usr/bin/python3 -m pip install \"black==22.3.0\" --upgrade --user\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<div class=\"highlight\" style=\"background: \"><pre style=\"line-height: 125%;\"><span></span><span style=\"color: #007979; font-style: italic\"># from tvm.script import tir as T</span>\n",
              "\n",
              "<span style=\"color: #AA22FF\">@T</span><span style=\"color: #AA22FF; font-weight: bold\">.</span>prim_func\n",
              "<span style=\"color: #008000; font-weight: bold\">def</span> <span style=\"color: #0000FF\">main</span>(A: T<span style=\"color: #AA22FF; font-weight: bold\">.</span>Buffer((<span style=\"color: #008000\">128</span>, <span style=\"color: #008000\">128</span>), <span style=\"color: #BA2121\">&quot;float32&quot;</span>), B: T<span style=\"color: #AA22FF; font-weight: bold\">.</span>Buffer((<span style=\"color: #008000\">128</span>, <span style=\"color: #008000\">128</span>), <span style=\"color: #BA2121\">&quot;float32&quot;</span>), relu: T<span style=\"color: #AA22FF; font-weight: bold\">.</span>Buffer((<span style=\"color: #008000\">128</span>, <span style=\"color: #008000\">128</span>), <span style=\"color: #BA2121\">&quot;float32&quot;</span>)):\n",
              "    T<span style=\"color: #AA22FF; font-weight: bold\">.</span>func_attr({<span style=\"color: #BA2121\">&quot;global_symbol&quot;</span>: <span style=\"color: #BA2121\">&quot;main&quot;</span>, <span style=\"color: #BA2121\">&quot;tir.noalias&quot;</span>: T<span style=\"color: #AA22FF; font-weight: bold\">.</span>bool(<span style=\"color: #008000; font-weight: bold\">True</span>)})\n",
              "    <span style=\"color: #007979; font-style: italic\"># with T.block(&quot;root&quot;):</span>\n",
              "    matmul <span style=\"color: #AA22FF; font-weight: bold\">=</span> T<span style=\"color: #AA22FF; font-weight: bold\">.</span>alloc_buffer((<span style=\"color: #008000\">128</span>, <span style=\"color: #008000\">128</span>))\n",
              "    <span style=\"color: #008000; font-weight: bold\">for</span> i, j, k <span style=\"color: #008000; font-weight: bold\">in</span> T<span style=\"color: #AA22FF; font-weight: bold\">.</span>grid(<span style=\"color: #008000\">128</span>, <span style=\"color: #008000\">128</span>, <span style=\"color: #008000\">128</span>):\n",
              "        <span style=\"color: #008000; font-weight: bold\">with</span> T<span style=\"color: #AA22FF; font-weight: bold\">.</span>block(<span style=\"color: #BA2121\">&quot;matmul&quot;</span>):\n",
              "            v_i, v_j, v_k <span style=\"color: #AA22FF; font-weight: bold\">=</span> T<span style=\"color: #AA22FF; font-weight: bold\">.</span>axis<span style=\"color: #AA22FF; font-weight: bold\">.</span>remap(<span style=\"color: #BA2121\">&quot;SSR&quot;</span>, [i, j, k])\n",
              "            T<span style=\"color: #AA22FF; font-weight: bold\">.</span>reads(A[v_i, v_k], B[v_k, v_j])\n",
              "            T<span style=\"color: #AA22FF; font-weight: bold\">.</span>writes(matmul[v_i, v_j])\n",
              "            <span style=\"color: #008000; font-weight: bold\">with</span> T<span style=\"color: #AA22FF; font-weight: bold\">.</span>init():\n",
              "                matmul[v_i, v_j] <span style=\"color: #AA22FF; font-weight: bold\">=</span> T<span style=\"color: #AA22FF; font-weight: bold\">.</span>float32(<span style=\"color: #008000\">0</span>)\n",
              "            matmul[v_i, v_j] <span style=\"color: #AA22FF; font-weight: bold\">=</span> matmul[v_i, v_j] <span style=\"color: #AA22FF; font-weight: bold\">+</span> A[v_i, v_k] <span style=\"color: #AA22FF; font-weight: bold\">*</span> B[v_k, v_j]\n",
              "    <span style=\"color: #008000; font-weight: bold\">for</span> i0, i1 <span style=\"color: #008000; font-weight: bold\">in</span> T<span style=\"color: #AA22FF; font-weight: bold\">.</span>grid(<span style=\"color: #008000\">128</span>, <span style=\"color: #008000\">128</span>):\n",
              "        <span style=\"color: #008000; font-weight: bold\">with</span> T<span style=\"color: #AA22FF; font-weight: bold\">.</span>block(<span style=\"color: #BA2121\">&quot;relu&quot;</span>):\n",
              "            v_i0, v_i1 <span style=\"color: #AA22FF; font-weight: bold\">=</span> T<span style=\"color: #AA22FF; font-weight: bold\">.</span>axis<span style=\"color: #AA22FF; font-weight: bold\">.</span>remap(<span style=\"color: #BA2121\">&quot;SS&quot;</span>, [i0, i1])\n",
              "            T<span style=\"color: #AA22FF; font-weight: bold\">.</span>reads(matmul[v_i0, v_i1])\n",
              "            T<span style=\"color: #AA22FF; font-weight: bold\">.</span>writes(relu[v_i0, v_i1])\n",
              "            relu[v_i0, v_i1] <span style=\"color: #AA22FF; font-weight: bold\">=</span> T<span style=\"color: #AA22FF; font-weight: bold\">.</span>max(matmul[v_i0, v_i1], T<span style=\"color: #AA22FF; font-weight: bold\">.</span>float32(<span style=\"color: #008000\">0</span>))\n",
              "</pre></div>\n"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "note only A B D are passed in, and C omitted.\n",
        "\n",
        "above, we can see prim func create temp buffer for C/matmul.\n",
        "\n",
        "we can still pass in C. however, the fusion is less advanced."
      ],
      "metadata": {
        "id": "uhIgpeRijYMY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "te.create_prim_func([A, B, C, D]).show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 456
        },
        "id": "JYPdMieFjWEN",
        "outputId": "df85b023-4723-4bf3-d3bb-92fc9eed6c40"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/tvm/script/highlight.py:117: UserWarning: No module named 'black'\n",
            "To print formatted TVM script, please install the formatter 'Black':\n",
            "/usr/bin/python3 -m pip install \"black==22.3.0\" --upgrade --user\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<div class=\"highlight\" style=\"background: \"><pre style=\"line-height: 125%;\"><span></span><span style=\"color: #007979; font-style: italic\"># from tvm.script import tir as T</span>\n",
              "\n",
              "<span style=\"color: #AA22FF\">@T</span><span style=\"color: #AA22FF; font-weight: bold\">.</span>prim_func\n",
              "<span style=\"color: #008000; font-weight: bold\">def</span> <span style=\"color: #0000FF\">main</span>(A: T<span style=\"color: #AA22FF; font-weight: bold\">.</span>Buffer((<span style=\"color: #008000\">128</span>, <span style=\"color: #008000\">128</span>), <span style=\"color: #BA2121\">&quot;float32&quot;</span>), B: T<span style=\"color: #AA22FF; font-weight: bold\">.</span>Buffer((<span style=\"color: #008000\">128</span>, <span style=\"color: #008000\">128</span>), <span style=\"color: #BA2121\">&quot;float32&quot;</span>), matmul: T<span style=\"color: #AA22FF; font-weight: bold\">.</span>Buffer((<span style=\"color: #008000\">128</span>, <span style=\"color: #008000\">128</span>), <span style=\"color: #BA2121\">&quot;float32&quot;</span>), relu: T<span style=\"color: #AA22FF; font-weight: bold\">.</span>Buffer((<span style=\"color: #008000\">128</span>, <span style=\"color: #008000\">128</span>), <span style=\"color: #BA2121\">&quot;float32&quot;</span>)):\n",
              "    T<span style=\"color: #AA22FF; font-weight: bold\">.</span>func_attr({<span style=\"color: #BA2121\">&quot;global_symbol&quot;</span>: <span style=\"color: #BA2121\">&quot;main&quot;</span>, <span style=\"color: #BA2121\">&quot;tir.noalias&quot;</span>: T<span style=\"color: #AA22FF; font-weight: bold\">.</span>bool(<span style=\"color: #008000; font-weight: bold\">True</span>)})\n",
              "    <span style=\"color: #007979; font-style: italic\"># with T.block(&quot;root&quot;):</span>\n",
              "    <span style=\"color: #008000; font-weight: bold\">for</span> i, j, k <span style=\"color: #008000; font-weight: bold\">in</span> T<span style=\"color: #AA22FF; font-weight: bold\">.</span>grid(<span style=\"color: #008000\">128</span>, <span style=\"color: #008000\">128</span>, <span style=\"color: #008000\">128</span>):\n",
              "        <span style=\"color: #008000; font-weight: bold\">with</span> T<span style=\"color: #AA22FF; font-weight: bold\">.</span>block(<span style=\"color: #BA2121\">&quot;matmul&quot;</span>):\n",
              "            v_i, v_j, v_k <span style=\"color: #AA22FF; font-weight: bold\">=</span> T<span style=\"color: #AA22FF; font-weight: bold\">.</span>axis<span style=\"color: #AA22FF; font-weight: bold\">.</span>remap(<span style=\"color: #BA2121\">&quot;SSR&quot;</span>, [i, j, k])\n",
              "            T<span style=\"color: #AA22FF; font-weight: bold\">.</span>reads(A[v_i, v_k], B[v_k, v_j])\n",
              "            T<span style=\"color: #AA22FF; font-weight: bold\">.</span>writes(matmul[v_i, v_j])\n",
              "            <span style=\"color: #008000; font-weight: bold\">with</span> T<span style=\"color: #AA22FF; font-weight: bold\">.</span>init():\n",
              "                matmul[v_i, v_j] <span style=\"color: #AA22FF; font-weight: bold\">=</span> T<span style=\"color: #AA22FF; font-weight: bold\">.</span>float32(<span style=\"color: #008000\">0</span>)\n",
              "            matmul[v_i, v_j] <span style=\"color: #AA22FF; font-weight: bold\">=</span> matmul[v_i, v_j] <span style=\"color: #AA22FF; font-weight: bold\">+</span> A[v_i, v_k] <span style=\"color: #AA22FF; font-weight: bold\">*</span> B[v_k, v_j]\n",
              "    <span style=\"color: #008000; font-weight: bold\">for</span> i0, i1 <span style=\"color: #008000; font-weight: bold\">in</span> T<span style=\"color: #AA22FF; font-weight: bold\">.</span>grid(<span style=\"color: #008000\">128</span>, <span style=\"color: #008000\">128</span>):\n",
              "        <span style=\"color: #008000; font-weight: bold\">with</span> T<span style=\"color: #AA22FF; font-weight: bold\">.</span>block(<span style=\"color: #BA2121\">&quot;relu&quot;</span>):\n",
              "            v_i0, v_i1 <span style=\"color: #AA22FF; font-weight: bold\">=</span> T<span style=\"color: #AA22FF; font-weight: bold\">.</span>axis<span style=\"color: #AA22FF; font-weight: bold\">.</span>remap(<span style=\"color: #BA2121\">&quot;SS&quot;</span>, [i0, i1])\n",
              "            T<span style=\"color: #AA22FF; font-weight: bold\">.</span>reads(matmul[v_i0, v_i1])\n",
              "            T<span style=\"color: #AA22FF; font-weight: bold\">.</span>writes(relu[v_i0, v_i1])\n",
              "            relu[v_i0, v_i1] <span style=\"color: #AA22FF; font-weight: bold\">=</span> T<span style=\"color: #AA22FF; font-weight: bold\">.</span>max(matmul[v_i0, v_i1], T<span style=\"color: #AA22FF; font-weight: bold\">.</span>float32(<span style=\"color: #008000\">0</span>))\n",
              "</pre></div>\n"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "note how C/matmul is passed in."
      ],
      "metadata": {
        "id": "P9SY6oHzkCIQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Connect IRModules via BlockBuilder \n",
        "\n",
        "build end to end model with IRModule defined above"
      ],
      "metadata": {
        "id": "ljzoFsZ2kO4G"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# define input\n",
        "A = relax.Var(\"A\", relax.TensorStructInfo((128, 128), f32))\n",
        "B = relax.Var(\"B\", relax.TensorStructInfo((128, 128), f32))\n",
        "\n",
        "# create block builder\n",
        "bb = relax.BlockBuilder()\n",
        "\n",
        "with bb.function(\"main\"):\n",
        "    with bb.dataflow():\n",
        "        C = bb.emit_te(te_matmul, A, B)\n",
        "        D = bb.emit_te(te_relu, C)\n",
        "        R = bb.emit_output(D)\n",
        "    bb.emit_func_output(R, params=[A, B])\n",
        "\n",
        "# show IRModule\n",
        "MyModule = bb.get()\n",
        "print(type(MyModule))\n",
        "MyModule.show()"
      ],
      "metadata": {
        "id": "xvNmP7elax5p",
        "outputId": "f5708eea-c1fb-424f-85b0-c2e78d0b3bad",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 806
        }
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'tvm.ir.module.IRModule'>\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/tvm/script/highlight.py:117: UserWarning: No module named 'black'\n",
            "To print formatted TVM script, please install the formatter 'Black':\n",
            "/usr/bin/python3 -m pip install \"black==22.3.0\" --upgrade --user\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<div class=\"highlight\" style=\"background: \"><pre style=\"line-height: 125%;\"><span></span><span style=\"color: #007979; font-style: italic\"># from tvm.script import ir as I</span>\n",
              "<span style=\"color: #007979; font-style: italic\"># from tvm.script import tir as T</span>\n",
              "<span style=\"color: #007979; font-style: italic\"># from tvm.script import relax as R</span>\n",
              "\n",
              "<span style=\"color: #AA22FF\">@I</span><span style=\"color: #AA22FF; font-weight: bold\">.</span>ir_module\n",
              "<span style=\"color: #008000; font-weight: bold\">class</span> <span style=\"color: #0000FF; font-weight: bold\">Module</span>:\n",
              "    <span style=\"color: #AA22FF\">@T</span><span style=\"color: #AA22FF; font-weight: bold\">.</span>prim_func\n",
              "    <span style=\"color: #008000; font-weight: bold\">def</span> <span style=\"color: #0000FF\">te_matmul</span>(A: T<span style=\"color: #AA22FF; font-weight: bold\">.</span>Buffer((T<span style=\"color: #AA22FF; font-weight: bold\">.</span>int64(<span style=\"color: #008000\">128</span>), T<span style=\"color: #AA22FF; font-weight: bold\">.</span>int64(<span style=\"color: #008000\">128</span>)), <span style=\"color: #BA2121\">&quot;float32&quot;</span>), B: T<span style=\"color: #AA22FF; font-weight: bold\">.</span>Buffer((T<span style=\"color: #AA22FF; font-weight: bold\">.</span>int64(<span style=\"color: #008000\">128</span>), T<span style=\"color: #AA22FF; font-weight: bold\">.</span>int64(<span style=\"color: #008000\">128</span>)), <span style=\"color: #BA2121\">&quot;float32&quot;</span>), matmul: T<span style=\"color: #AA22FF; font-weight: bold\">.</span>Buffer((T<span style=\"color: #AA22FF; font-weight: bold\">.</span>int64(<span style=\"color: #008000\">128</span>), T<span style=\"color: #AA22FF; font-weight: bold\">.</span>int64(<span style=\"color: #008000\">128</span>)), <span style=\"color: #BA2121\">&quot;float32&quot;</span>)):\n",
              "        T<span style=\"color: #AA22FF; font-weight: bold\">.</span>func_attr({<span style=\"color: #BA2121\">&quot;tir.noalias&quot;</span>: T<span style=\"color: #AA22FF; font-weight: bold\">.</span>bool(<span style=\"color: #008000; font-weight: bold\">True</span>)})\n",
              "        <span style=\"color: #007979; font-style: italic\"># with T.block(&quot;root&quot;):</span>\n",
              "        <span style=\"color: #008000; font-weight: bold\">for</span> i, j, k <span style=\"color: #008000; font-weight: bold\">in</span> T<span style=\"color: #AA22FF; font-weight: bold\">.</span>grid(T<span style=\"color: #AA22FF; font-weight: bold\">.</span>int64(<span style=\"color: #008000\">128</span>), T<span style=\"color: #AA22FF; font-weight: bold\">.</span>int64(<span style=\"color: #008000\">128</span>), T<span style=\"color: #AA22FF; font-weight: bold\">.</span>int64(<span style=\"color: #008000\">128</span>)):\n",
              "            <span style=\"color: #008000; font-weight: bold\">with</span> T<span style=\"color: #AA22FF; font-weight: bold\">.</span>block(<span style=\"color: #BA2121\">&quot;matmul&quot;</span>):\n",
              "                v_i, v_j, v_k <span style=\"color: #AA22FF; font-weight: bold\">=</span> T<span style=\"color: #AA22FF; font-weight: bold\">.</span>axis<span style=\"color: #AA22FF; font-weight: bold\">.</span>remap(<span style=\"color: #BA2121\">&quot;SSR&quot;</span>, [i, j, k])\n",
              "                T<span style=\"color: #AA22FF; font-weight: bold\">.</span>reads(A[v_i, v_k], B[v_k, v_j])\n",
              "                T<span style=\"color: #AA22FF; font-weight: bold\">.</span>writes(matmul[v_i, v_j])\n",
              "                <span style=\"color: #008000; font-weight: bold\">with</span> T<span style=\"color: #AA22FF; font-weight: bold\">.</span>init():\n",
              "                    matmul[v_i, v_j] <span style=\"color: #AA22FF; font-weight: bold\">=</span> T<span style=\"color: #AA22FF; font-weight: bold\">.</span>float32(<span style=\"color: #008000\">0</span>)\n",
              "                matmul[v_i, v_j] <span style=\"color: #AA22FF; font-weight: bold\">=</span> matmul[v_i, v_j] <span style=\"color: #AA22FF; font-weight: bold\">+</span> A[v_i, v_k] <span style=\"color: #AA22FF; font-weight: bold\">*</span> B[v_k, v_j]\n",
              "\n",
              "    <span style=\"color: #AA22FF\">@T</span><span style=\"color: #AA22FF; font-weight: bold\">.</span>prim_func\n",
              "    <span style=\"color: #008000; font-weight: bold\">def</span> <span style=\"color: #0000FF\">te_relu</span>(A: T<span style=\"color: #AA22FF; font-weight: bold\">.</span>Buffer((T<span style=\"color: #AA22FF; font-weight: bold\">.</span>int64(<span style=\"color: #008000\">128</span>), T<span style=\"color: #AA22FF; font-weight: bold\">.</span>int64(<span style=\"color: #008000\">128</span>)), <span style=\"color: #BA2121\">&quot;float32&quot;</span>), relu: T<span style=\"color: #AA22FF; font-weight: bold\">.</span>Buffer((T<span style=\"color: #AA22FF; font-weight: bold\">.</span>int64(<span style=\"color: #008000\">128</span>), T<span style=\"color: #AA22FF; font-weight: bold\">.</span>int64(<span style=\"color: #008000\">128</span>)), <span style=\"color: #BA2121\">&quot;float32&quot;</span>)):\n",
              "        T<span style=\"color: #AA22FF; font-weight: bold\">.</span>func_attr({<span style=\"color: #BA2121\">&quot;tir.noalias&quot;</span>: T<span style=\"color: #AA22FF; font-weight: bold\">.</span>bool(<span style=\"color: #008000; font-weight: bold\">True</span>)})\n",
              "        <span style=\"color: #007979; font-style: italic\"># with T.block(&quot;root&quot;):</span>\n",
              "        <span style=\"color: #008000; font-weight: bold\">for</span> i0, i1 <span style=\"color: #008000; font-weight: bold\">in</span> T<span style=\"color: #AA22FF; font-weight: bold\">.</span>grid(T<span style=\"color: #AA22FF; font-weight: bold\">.</span>int64(<span style=\"color: #008000\">128</span>), T<span style=\"color: #AA22FF; font-weight: bold\">.</span>int64(<span style=\"color: #008000\">128</span>)):\n",
              "            <span style=\"color: #008000; font-weight: bold\">with</span> T<span style=\"color: #AA22FF; font-weight: bold\">.</span>block(<span style=\"color: #BA2121\">&quot;relu&quot;</span>):\n",
              "                v_i0, v_i1 <span style=\"color: #AA22FF; font-weight: bold\">=</span> T<span style=\"color: #AA22FF; font-weight: bold\">.</span>axis<span style=\"color: #AA22FF; font-weight: bold\">.</span>remap(<span style=\"color: #BA2121\">&quot;SS&quot;</span>, [i0, i1])\n",
              "                T<span style=\"color: #AA22FF; font-weight: bold\">.</span>reads(A[v_i0, v_i1])\n",
              "                T<span style=\"color: #AA22FF; font-weight: bold\">.</span>writes(relu[v_i0, v_i1])\n",
              "                relu[v_i0, v_i1] <span style=\"color: #AA22FF; font-weight: bold\">=</span> T<span style=\"color: #AA22FF; font-weight: bold\">.</span>max(A[v_i0, v_i1], T<span style=\"color: #AA22FF; font-weight: bold\">.</span>float32(<span style=\"color: #008000\">0</span>))\n",
              "\n",
              "    <span style=\"color: #AA22FF\">@R</span><span style=\"color: #AA22FF; font-weight: bold\">.</span>function\n",
              "    <span style=\"color: #008000; font-weight: bold\">def</span> <span style=\"color: #0000FF\">main</span>(A: R<span style=\"color: #AA22FF; font-weight: bold\">.</span>Tensor((<span style=\"color: #008000\">128</span>, <span style=\"color: #008000\">128</span>), dtype<span style=\"color: #AA22FF; font-weight: bold\">=</span><span style=\"color: #BA2121\">&quot;float32&quot;</span>), B: R<span style=\"color: #AA22FF; font-weight: bold\">.</span>Tensor((<span style=\"color: #008000\">128</span>, <span style=\"color: #008000\">128</span>), dtype<span style=\"color: #AA22FF; font-weight: bold\">=</span><span style=\"color: #BA2121\">&quot;float32&quot;</span>)) <span style=\"color: #AA22FF; font-weight: bold\">-&gt;</span> R<span style=\"color: #AA22FF; font-weight: bold\">.</span>Tensor((<span style=\"color: #008000\">128</span>, <span style=\"color: #008000\">128</span>), dtype<span style=\"color: #AA22FF; font-weight: bold\">=</span><span style=\"color: #BA2121\">&quot;float32&quot;</span>):\n",
              "        cls <span style=\"color: #AA22FF; font-weight: bold\">=</span> Module\n",
              "        <span style=\"color: #008000; font-weight: bold\">with</span> R<span style=\"color: #AA22FF; font-weight: bold\">.</span>dataflow():\n",
              "            lv <span style=\"color: #AA22FF; font-weight: bold\">=</span> R<span style=\"color: #AA22FF; font-weight: bold\">.</span>call_tir(cls<span style=\"color: #AA22FF; font-weight: bold\">.</span>te_matmul, (A, B), out_sinfo<span style=\"color: #AA22FF; font-weight: bold\">=</span>R<span style=\"color: #AA22FF; font-weight: bold\">.</span>Tensor((<span style=\"color: #008000\">128</span>, <span style=\"color: #008000\">128</span>), dtype<span style=\"color: #AA22FF; font-weight: bold\">=</span><span style=\"color: #BA2121\">&quot;float32&quot;</span>))\n",
              "            lv1 <span style=\"color: #AA22FF; font-weight: bold\">=</span> R<span style=\"color: #AA22FF; font-weight: bold\">.</span>call_tir(cls<span style=\"color: #AA22FF; font-weight: bold\">.</span>te_relu, (lv,), out_sinfo<span style=\"color: #AA22FF; font-weight: bold\">=</span>R<span style=\"color: #AA22FF; font-weight: bold\">.</span>Tensor((<span style=\"color: #008000\">128</span>, <span style=\"color: #008000\">128</span>), dtype<span style=\"color: #AA22FF; font-weight: bold\">=</span><span style=\"color: #BA2121\">&quot;float32&quot;</span>))\n",
              "            gv: R<span style=\"color: #AA22FF; font-weight: bold\">.</span>Tensor((<span style=\"color: #008000\">128</span>, <span style=\"color: #008000\">128</span>), dtype<span style=\"color: #AA22FF; font-weight: bold\">=</span><span style=\"color: #BA2121\">&quot;float32&quot;</span>) <span style=\"color: #AA22FF; font-weight: bold\">=</span> lv1\n",
              "            R<span style=\"color: #AA22FF; font-weight: bold\">.</span>output(gv)\n",
              "        <span style=\"color: #008000; font-weight: bold\">return</span> gv\n",
              "</pre></div>\n"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "compare this model to the end-to-end model in last notebook:\n",
        "\n",
        "- pretty much the same\n",
        "- much less code wrote to achieve"
      ],
      "metadata": {
        "id": "jsCaZZQHcPXC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Import model from PyTorch\n",
        "\n",
        "now we know how to construct an IRModule programmatically.\n",
        "\n",
        "lets convert a PyTorch model into IRModule format."
      ],
      "metadata": {
        "id": "Tt_YeYelctS1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# define the PyTorch model (and convert it to IRModule)\n",
        "class MyModel(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(MyModel, self).__init__()\n",
        "        self.weight = nn.Parameter(torch.randn(128, 128))\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = torch.matmul(x, self.weight)\n",
        "        x = torch.relu(x)\n",
        "        return x"
      ],
      "metadata": {
        "id": "qoe5z6pehZaC"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### TorchFX\n",
        "\n",
        "to trace a graph of PyTorch model.  \n",
        "(util tool to visualize model)"
      ],
      "metadata": {
        "id": "viFiFmfKiieK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = MyModel()\n",
        "fx_module = fx.symbolic_trace(model)\n",
        "fx_module.graph.print_tabular()"
      ],
      "metadata": {
        "id": "Z-zQXKscicTZ",
        "outputId": "7f5e7b1f-890d-4aab-cd88-54b2850bac2a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "opcode         name    target                                                     args         kwargs\n",
            "-------------  ------  ---------------------------------------------------------  -----------  --------\n",
            "placeholder    x       x                                                          ()           {}\n",
            "get_attr       weight  weight                                                     ()           {}\n",
            "call_function  matmul  <built-in method matmul of type object at 0x7f751658e880>  (x, weight)  {}\n",
            "call_function  relu    <built-in method relu of type object at 0x7f751658e880>    (matmul,)    {}\n",
            "output         output  output                                                     (relu,)      {}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for node in fx_module.graph.nodes:\n",
        "    print(node.op)"
      ],
      "metadata": {
        "id": "PuGtlkAqm6th",
        "outputId": "29080622-da32-4a4b-f2c1-2e68ccbab4af",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "placeholder\n",
            "get_attr\n",
            "call_function\n",
            "call_function\n",
            "output\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Create Map Func\n",
        "\n",
        "workflow:\n",
        "1. create `node_map` to map `fx.Node` to `relax.Var`\n",
        "2. iterate over nodes in `fx.graph` in topological order\n",
        "3. compute mapped output"
      ],
      "metadata": {
        "id": "Q2KFUw8MjHGj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def map_param(param: nn.Parameter):\n",
        "    \"\"\"helper func\"\"\"\n",
        "    ndim = len(param.data.shape)\n",
        "    return relax.const(\n",
        "        param.data.cpu().numpy(), relax.DynTensorType(ndim, \"float32\")\n",
        "    )\n",
        "\n",
        "def fetch_attr(fx_mod, target: str):\n",
        "    \"\"\"helper func\"\"\"\n",
        "    target_atoms = target.split('.')\n",
        "    attr_itr = fx_mod\n",
        "    for i, atom, in enumerate(target_atoms):\n",
        "        if not hasattr(attr_itr, atom):\n",
        "            raise RuntimeError(f\"Node referenced nonexistant target {'.'.join(target_atoms[:i])}\")\n",
        "        attr_itr = getattr(attr_itr, atom)\n",
        "    return attr_itr\n",
        "\n",
        "def from_fx(fx_mod, input_shapes, call_function_map, call_module_map):\n",
        "    input_index = 0\n",
        "    node_map = {}\n",
        "    named_modules = dict(fx_mod.named_modules())\n",
        "\n",
        "    bb = relax.BlockBuilder()\n",
        "\n",
        "    fn_inputs = []\n",
        "    fn_output = None\n",
        "    with bb.function(\"main\"):\n",
        "        with bb.dataflow():\n",
        "            for node in fx_mod.graph.nodes:\n",
        "                if node.op == 'placeholder': # found input vars\n",
        "                    shape = input_shapes[input_index]\n",
        "                    input_index += 1\n",
        "                    input_var = relax.Var(\n",
        "                        node.target, relax.TensorStructInfo(shape, f32)\n",
        "                    )\n",
        "                    fn_inputs.append(input_var)\n",
        "                    node_map[node] = input_var\n",
        "                elif node.op == 'get_attr': # found parameters\n",
        "                    attr = fetch_attr(fx_mod, node.target)\n",
        "                    param = map_param(attr)\n",
        "                    node_map[node] = param\n",
        "                elif node.op == 'call_function': # found a func\n",
        "                    func = call_function_map[node.target](bb, node_map, node)\n",
        "                    node_map[node] = func\n",
        "                elif node.op == 'call_module': # this one D.N.E in our example\n",
        "                    named_module = named_modules[node.target]\n",
        "                    node_map[node] = call_module_map[type(named_module)](bb, node_map, node, named_module)\n",
        "                elif node.op == 'output': # found output\n",
        "                    output = node_map[node.args[0]]\n",
        "                    assert fn_output is None\n",
        "                    fn_output = bb.emit_output(output)\n",
        "        bb.emit_func_output(fn_output, fn_inputs)\n",
        "    return bb.get()\n",
        "\n"
      ],
      "metadata": {
        "id": "9r4Pg1oujDDo"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# supply translation rule via map\n",
        "def map_matmul(bb, node_map, node: fx.Node):\n",
        "    A = node_map[node.args[0]]\n",
        "    B = node_map[node.args[1]]\n",
        "    return bb.emit_te(te_matmul, A, B)\n",
        "\n",
        "def map_relu(bb, node_map, node: fx.Node):\n",
        "    A = node_map[node.args[0]]\n",
        "    return bb.emit_te(te_relu, A)"
      ],
      "metadata": {
        "id": "M4yxPai0oIy0"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# create IRModule\n",
        "MyModule = from_fx(\n",
        "    fx_module,\n",
        "    input_shapes = [(1, 128)],\n",
        "    call_function_map = {\n",
        "      torch.matmul: map_matmul,\n",
        "      torch.relu: map_relu,\n",
        "    },\n",
        "    call_module_map={},\n",
        ")\n",
        "\n",
        "MyModule.show()"
      ],
      "metadata": {
        "id": "lwn-eBnWovwW",
        "outputId": "20b3d091-c9a7-4218-c45b-08be0220a02a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 824
        }
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/tvm/script/highlight.py:117: UserWarning: No module named 'black'\n",
            "To print formatted TVM script, please install the formatter 'Black':\n",
            "/usr/bin/python3 -m pip install \"black==22.3.0\" --upgrade --user\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<div class=\"highlight\" style=\"background: \"><pre style=\"line-height: 125%;\"><span></span><span style=\"color: #007979; font-style: italic\"># from tvm.script import ir as I</span>\n",
              "<span style=\"color: #007979; font-style: italic\"># from tvm.script import tir as T</span>\n",
              "<span style=\"color: #007979; font-style: italic\"># from tvm.script import relax as R</span>\n",
              "\n",
              "<span style=\"color: #AA22FF\">@I</span><span style=\"color: #AA22FF; font-weight: bold\">.</span>ir_module\n",
              "<span style=\"color: #008000; font-weight: bold\">class</span> <span style=\"color: #0000FF; font-weight: bold\">Module</span>:\n",
              "    <span style=\"color: #AA22FF\">@T</span><span style=\"color: #AA22FF; font-weight: bold\">.</span>prim_func\n",
              "    <span style=\"color: #008000; font-weight: bold\">def</span> <span style=\"color: #0000FF\">te_matmul</span>(A: T<span style=\"color: #AA22FF; font-weight: bold\">.</span>Buffer((T<span style=\"color: #AA22FF; font-weight: bold\">.</span>int64(<span style=\"color: #008000\">1</span>), T<span style=\"color: #AA22FF; font-weight: bold\">.</span>int64(<span style=\"color: #008000\">128</span>)), <span style=\"color: #BA2121\">&quot;float32&quot;</span>), B: T<span style=\"color: #AA22FF; font-weight: bold\">.</span>Buffer((T<span style=\"color: #AA22FF; font-weight: bold\">.</span>int64(<span style=\"color: #008000\">128</span>), T<span style=\"color: #AA22FF; font-weight: bold\">.</span>int64(<span style=\"color: #008000\">128</span>)), <span style=\"color: #BA2121\">&quot;float32&quot;</span>), matmul: T<span style=\"color: #AA22FF; font-weight: bold\">.</span>Buffer((T<span style=\"color: #AA22FF; font-weight: bold\">.</span>int64(<span style=\"color: #008000\">1</span>), T<span style=\"color: #AA22FF; font-weight: bold\">.</span>int64(<span style=\"color: #008000\">128</span>)), <span style=\"color: #BA2121\">&quot;float32&quot;</span>)):\n",
              "        T<span style=\"color: #AA22FF; font-weight: bold\">.</span>func_attr({<span style=\"color: #BA2121\">&quot;tir.noalias&quot;</span>: T<span style=\"color: #AA22FF; font-weight: bold\">.</span>bool(<span style=\"color: #008000; font-weight: bold\">True</span>)})\n",
              "        <span style=\"color: #007979; font-style: italic\"># with T.block(&quot;root&quot;):</span>\n",
              "        <span style=\"color: #008000; font-weight: bold\">for</span> i, j, k <span style=\"color: #008000; font-weight: bold\">in</span> T<span style=\"color: #AA22FF; font-weight: bold\">.</span>grid(T<span style=\"color: #AA22FF; font-weight: bold\">.</span>int64(<span style=\"color: #008000\">1</span>), T<span style=\"color: #AA22FF; font-weight: bold\">.</span>int64(<span style=\"color: #008000\">128</span>), T<span style=\"color: #AA22FF; font-weight: bold\">.</span>int64(<span style=\"color: #008000\">128</span>)):\n",
              "            <span style=\"color: #008000; font-weight: bold\">with</span> T<span style=\"color: #AA22FF; font-weight: bold\">.</span>block(<span style=\"color: #BA2121\">&quot;matmul&quot;</span>):\n",
              "                v_i, v_j, v_k <span style=\"color: #AA22FF; font-weight: bold\">=</span> T<span style=\"color: #AA22FF; font-weight: bold\">.</span>axis<span style=\"color: #AA22FF; font-weight: bold\">.</span>remap(<span style=\"color: #BA2121\">&quot;SSR&quot;</span>, [i, j, k])\n",
              "                T<span style=\"color: #AA22FF; font-weight: bold\">.</span>reads(A[v_i, v_k], B[v_k, v_j])\n",
              "                T<span style=\"color: #AA22FF; font-weight: bold\">.</span>writes(matmul[v_i, v_j])\n",
              "                <span style=\"color: #008000; font-weight: bold\">with</span> T<span style=\"color: #AA22FF; font-weight: bold\">.</span>init():\n",
              "                    matmul[v_i, v_j] <span style=\"color: #AA22FF; font-weight: bold\">=</span> T<span style=\"color: #AA22FF; font-weight: bold\">.</span>float32(<span style=\"color: #008000\">0</span>)\n",
              "                matmul[v_i, v_j] <span style=\"color: #AA22FF; font-weight: bold\">=</span> matmul[v_i, v_j] <span style=\"color: #AA22FF; font-weight: bold\">+</span> A[v_i, v_k] <span style=\"color: #AA22FF; font-weight: bold\">*</span> B[v_k, v_j]\n",
              "\n",
              "    <span style=\"color: #AA22FF\">@T</span><span style=\"color: #AA22FF; font-weight: bold\">.</span>prim_func\n",
              "    <span style=\"color: #008000; font-weight: bold\">def</span> <span style=\"color: #0000FF\">te_relu</span>(A: T<span style=\"color: #AA22FF; font-weight: bold\">.</span>Buffer((T<span style=\"color: #AA22FF; font-weight: bold\">.</span>int64(<span style=\"color: #008000\">1</span>), T<span style=\"color: #AA22FF; font-weight: bold\">.</span>int64(<span style=\"color: #008000\">128</span>)), <span style=\"color: #BA2121\">&quot;float32&quot;</span>), relu: T<span style=\"color: #AA22FF; font-weight: bold\">.</span>Buffer((T<span style=\"color: #AA22FF; font-weight: bold\">.</span>int64(<span style=\"color: #008000\">1</span>), T<span style=\"color: #AA22FF; font-weight: bold\">.</span>int64(<span style=\"color: #008000\">128</span>)), <span style=\"color: #BA2121\">&quot;float32&quot;</span>)):\n",
              "        T<span style=\"color: #AA22FF; font-weight: bold\">.</span>func_attr({<span style=\"color: #BA2121\">&quot;tir.noalias&quot;</span>: T<span style=\"color: #AA22FF; font-weight: bold\">.</span>bool(<span style=\"color: #008000; font-weight: bold\">True</span>)})\n",
              "        <span style=\"color: #007979; font-style: italic\"># with T.block(&quot;root&quot;):</span>\n",
              "        <span style=\"color: #008000; font-weight: bold\">for</span> i0, i1 <span style=\"color: #008000; font-weight: bold\">in</span> T<span style=\"color: #AA22FF; font-weight: bold\">.</span>grid(T<span style=\"color: #AA22FF; font-weight: bold\">.</span>int64(<span style=\"color: #008000\">1</span>), T<span style=\"color: #AA22FF; font-weight: bold\">.</span>int64(<span style=\"color: #008000\">128</span>)):\n",
              "            <span style=\"color: #008000; font-weight: bold\">with</span> T<span style=\"color: #AA22FF; font-weight: bold\">.</span>block(<span style=\"color: #BA2121\">&quot;relu&quot;</span>):\n",
              "                v_i0, v_i1 <span style=\"color: #AA22FF; font-weight: bold\">=</span> T<span style=\"color: #AA22FF; font-weight: bold\">.</span>axis<span style=\"color: #AA22FF; font-weight: bold\">.</span>remap(<span style=\"color: #BA2121\">&quot;SS&quot;</span>, [i0, i1])\n",
              "                T<span style=\"color: #AA22FF; font-weight: bold\">.</span>reads(A[v_i0, v_i1])\n",
              "                T<span style=\"color: #AA22FF; font-weight: bold\">.</span>writes(relu[v_i0, v_i1])\n",
              "                relu[v_i0, v_i1] <span style=\"color: #AA22FF; font-weight: bold\">=</span> T<span style=\"color: #AA22FF; font-weight: bold\">.</span>max(A[v_i0, v_i1], T<span style=\"color: #AA22FF; font-weight: bold\">.</span>float32(<span style=\"color: #008000\">0</span>))\n",
              "\n",
              "    <span style=\"color: #AA22FF\">@R</span><span style=\"color: #AA22FF; font-weight: bold\">.</span>function\n",
              "    <span style=\"color: #008000; font-weight: bold\">def</span> <span style=\"color: #0000FF\">main</span>(x: R<span style=\"color: #AA22FF; font-weight: bold\">.</span>Tensor((<span style=\"color: #008000\">1</span>, <span style=\"color: #008000\">128</span>), dtype<span style=\"color: #AA22FF; font-weight: bold\">=</span><span style=\"color: #BA2121\">&quot;float32&quot;</span>)) <span style=\"color: #AA22FF; font-weight: bold\">-&gt;</span> R<span style=\"color: #AA22FF; font-weight: bold\">.</span>Tensor((<span style=\"color: #008000\">1</span>, <span style=\"color: #008000\">128</span>), dtype<span style=\"color: #AA22FF; font-weight: bold\">=</span><span style=\"color: #BA2121\">&quot;float32&quot;</span>):\n",
              "        cls <span style=\"color: #AA22FF; font-weight: bold\">=</span> Module\n",
              "        <span style=\"color: #008000; font-weight: bold\">with</span> R<span style=\"color: #AA22FF; font-weight: bold\">.</span>dataflow():\n",
              "            lv <span style=\"color: #AA22FF; font-weight: bold\">=</span> R<span style=\"color: #AA22FF; font-weight: bold\">.</span>call_tir(cls<span style=\"color: #AA22FF; font-weight: bold\">.</span>te_matmul, (x, metadata[<span style=\"color: #BA2121\">&quot;relax.expr.Constant&quot;</span>][<span style=\"color: #008000\">0</span>]), out_sinfo<span style=\"color: #AA22FF; font-weight: bold\">=</span>R<span style=\"color: #AA22FF; font-weight: bold\">.</span>Tensor((<span style=\"color: #008000\">1</span>, <span style=\"color: #008000\">128</span>), dtype<span style=\"color: #AA22FF; font-weight: bold\">=</span><span style=\"color: #BA2121\">&quot;float32&quot;</span>))\n",
              "            lv1 <span style=\"color: #AA22FF; font-weight: bold\">=</span> R<span style=\"color: #AA22FF; font-weight: bold\">.</span>call_tir(cls<span style=\"color: #AA22FF; font-weight: bold\">.</span>te_relu, (lv,), out_sinfo<span style=\"color: #AA22FF; font-weight: bold\">=</span>R<span style=\"color: #AA22FF; font-weight: bold\">.</span>Tensor((<span style=\"color: #008000\">1</span>, <span style=\"color: #008000\">128</span>), dtype<span style=\"color: #AA22FF; font-weight: bold\">=</span><span style=\"color: #BA2121\">&quot;float32&quot;</span>))\n",
              "            gv: R<span style=\"color: #AA22FF; font-weight: bold\">.</span>Tensor((<span style=\"color: #008000\">1</span>, <span style=\"color: #008000\">128</span>), dtype<span style=\"color: #AA22FF; font-weight: bold\">=</span><span style=\"color: #BA2121\">&quot;float32&quot;</span>) <span style=\"color: #AA22FF; font-weight: bold\">=</span> lv1\n",
              "            R<span style=\"color: #AA22FF; font-weight: bold\">.</span>output(gv)\n",
              "        <span style=\"color: #008000; font-weight: bold\">return</span> lv1\n",
              "\n",
              "<span style=\"color: #007979; font-style: italic\"># Metadata omitted. Use show_meta=True in script() method to show it.</span>\n",
              "</pre></div>\n"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# FashionMNIST example\n",
        "\n",
        "rewrite end to end model, FashionMNIST, using te and blockbuilder."
      ],
      "metadata": {
        "id": "w6em1kvBW8CA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torchvision\n",
        "\n",
        "# load data\n",
        "test_data = torchvision.datasets.FashionMNIST(\n",
        "    root='data',\n",
        "    train=False,\n",
        "    download=True,\n",
        "    transform=torchvision.transforms.ToTensor()\n",
        ")\n",
        "test_loader = torch.utils.data.DataLoader(test_data, batch_size=1, shuffle=True)\n",
        "class_names = ['T-shirt/top', 'Trouser', 'Pullover', 'Dress', 'Coat',\n",
        "               'Sandal', 'Shirt', 'Sneaker', 'Bag', 'Ankle boot']\n",
        "img, label = next(iter(test_loader))\n",
        "print(img.shape)\n",
        "img = img.reshape(1, 28, 28).numpy()"
      ],
      "metadata": {
        "id": "e9gpsR0oov9Q",
        "outputId": "a91cb700-e608-4bf7-94b7-e1f49b039f02",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-images-idx3-ubyte.gz\n",
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-images-idx3-ubyte.gz to data/FashionMNIST/raw/train-images-idx3-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 26421880/26421880 [00:01<00:00, 17157771.94it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting data/FashionMNIST/raw/train-images-idx3-ubyte.gz to data/FashionMNIST/raw\n",
            "\n",
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-labels-idx1-ubyte.gz\n",
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-labels-idx1-ubyte.gz to data/FashionMNIST/raw/train-labels-idx1-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 29515/29515 [00:00<00:00, 302138.44it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting data/FashionMNIST/raw/train-labels-idx1-ubyte.gz to data/FashionMNIST/raw\n",
            "\n",
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-images-idx3-ubyte.gz\n",
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-images-idx3-ubyte.gz to data/FashionMNIST/raw/t10k-images-idx3-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 4422102/4422102 [00:00<00:00, 5525780.11it/s] \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting data/FashionMNIST/raw/t10k-images-idx3-ubyte.gz to data/FashionMNIST/raw\n",
            "\n",
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-labels-idx1-ubyte.gz\n",
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-labels-idx1-ubyte.gz to data/FashionMNIST/raw/t10k-labels-idx1-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 5148/5148 [00:00<00:00, 17301504.00it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting data/FashionMNIST/raw/t10k-labels-idx1-ubyte.gz to data/FashionMNIST/raw\n",
            "\n",
            "torch.Size([1, 1, 28, 28])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# plot img\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.figure()\n",
        "plt.imshow(img[0])\n",
        "plt.colorbar()\n",
        "plt.grid(False)\n",
        "plt.show()\n",
        "\n",
        "print(\"class:\", class_names[label[0]])"
      ],
      "metadata": {
        "id": "QI2zcMzHY9sy",
        "outputId": "a5868ffd-4e61-4a0d-a088-deb4d55715b2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 452
        }
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "class: T-shirt/top\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# download trained parameters\n",
        "import pickle as pkl\n",
        "\n",
        "!wget -nc https://github.com/mlc-ai/web-data/raw/main/models/fasionmnist_mlp_params.pkl\n",
        "mlp_params = pkl.load(open(\"fasionmnist_mlp_params.pkl\", \"rb\"))"
      ],
      "metadata": {
        "id": "ySlzW-YfZccL",
        "outputId": "1a39d623-a253-4586-9ad5-141b1d08feb1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "File ‘fasionmnist_mlp_params.pkl’ already there; not retrieving.\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# MLP model in pytorch (which will be converted to TensorIR Module)\n",
        "class MLP(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(MLP, self).__init__()\n",
        "        self.linear0 = nn.Linear(784, 128, bias=True)\n",
        "        self.relu = nn.ReLU()\n",
        "        self.linear1 = nn.Linear(128, 10, bias=True)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.linear0(x)\n",
        "        x = self.relu(x)\n",
        "        x = self.linear1(x)\n",
        "        return x"
      ],
      "metadata": {
        "id": "vGulLsoOZ72B"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# init mlp w/ param\n",
        "mlp_model = MLP()\n",
        "mlp_model.linear0.weight.data = torch.from_numpy(mlp_params[\"w0\"])\n",
        "mlp_model.linear0.bias.data = torch.from_numpy(mlp_params[\"b0\"])\n",
        "mlp_model.linear1.weight.data = torch.from_numpy(mlp_params[\"w1\"])\n",
        "mlp_model.linear1.bias.data = torch.from_numpy(mlp_params[\"b1\"])\n",
        "\n",
        "torch_res = mlp_model(torch.from_numpy(img.reshape(1, 784)))\n",
        "\n",
        "pred_kind = np.argmax(torch_res.detach().numpy(), axis=1)\n",
        "print(\"torch prediction\", class_names[pred_kind[0]])\n",
        "# success prediction"
      ],
      "metadata": {
        "id": "eiITO0Y-cewM",
        "outputId": "9a4b6430-5cc7-4773-9de5-9c941fc3ba88",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch prediction T-shirt/top\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Translate to IRModule"
      ],
      "metadata": {
        "id": "wluQ8NLYfckr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tvm import topi\n",
        "\n",
        "def map_nn_linear(bb, node_map, node, nn_mod):\n",
        "    x = node_map[node.args[0]]\n",
        "    w = map_param(nn_mod.weight)\n",
        "    if nn_mod.bias is not None:\n",
        "        b = map_param(nn_mod.bias)\n",
        "    y = bb.emit_te(topi.nn.dense, x, w)\n",
        "    z = bb.emit_te(topi.add, y, b)\n",
        "    return z\n",
        "\n",
        "def map_nn_relu(bb, node_map, node, nn_mod):\n",
        "    return map_relu(bb, node_map, node)\n",
        "\n",
        "# reuse from_fx function above\n",
        "MLPModule = from_fx(\n",
        "    fx.symbolic_trace(mlp_model),\n",
        "    input_shapes=[(1, 784)],\n",
        "    call_function_map={},\n",
        "    call_module_map={\n",
        "        torch.nn.Linear: map_nn_linear,\n",
        "        torch.nn.ReLU: map_nn_relu,\n",
        "    }\n",
        ")\n",
        "\n",
        "MLPModule.show()"
      ],
      "metadata": {
        "id": "xfx66fEXfmD5",
        "outputId": "a4891fc2-de35-4ba8-94b3-16152a54778a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/tvm/script/highlight.py:117: UserWarning: No module named 'black'\n",
            "To print formatted TVM script, please install the formatter 'Black':\n",
            "/usr/bin/python3 -m pip install \"black==22.3.0\" --upgrade --user\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<div class=\"highlight\" style=\"background: \"><pre style=\"line-height: 125%;\"><span></span><span style=\"color: #007979; font-style: italic\"># from tvm.script import ir as I</span>\n",
              "<span style=\"color: #007979; font-style: italic\"># from tvm.script import tir as T</span>\n",
              "<span style=\"color: #007979; font-style: italic\"># from tvm.script import relax as R</span>\n",
              "\n",
              "<span style=\"color: #AA22FF\">@I</span><span style=\"color: #AA22FF; font-weight: bold\">.</span>ir_module\n",
              "<span style=\"color: #008000; font-weight: bold\">class</span> <span style=\"color: #0000FF; font-weight: bold\">Module</span>:\n",
              "    <span style=\"color: #AA22FF\">@T</span><span style=\"color: #AA22FF; font-weight: bold\">.</span>prim_func\n",
              "    <span style=\"color: #008000; font-weight: bold\">def</span> <span style=\"color: #0000FF\">add</span>(A: T<span style=\"color: #AA22FF; font-weight: bold\">.</span>Buffer((T<span style=\"color: #AA22FF; font-weight: bold\">.</span>int64(<span style=\"color: #008000\">1</span>), T<span style=\"color: #AA22FF; font-weight: bold\">.</span>int64(<span style=\"color: #008000\">128</span>)), <span style=\"color: #BA2121\">&quot;float32&quot;</span>), B: T<span style=\"color: #AA22FF; font-weight: bold\">.</span>Buffer((T<span style=\"color: #AA22FF; font-weight: bold\">.</span>int64(<span style=\"color: #008000\">128</span>),), <span style=\"color: #BA2121\">&quot;float32&quot;</span>), T_add: T<span style=\"color: #AA22FF; font-weight: bold\">.</span>Buffer((T<span style=\"color: #AA22FF; font-weight: bold\">.</span>int64(<span style=\"color: #008000\">1</span>), T<span style=\"color: #AA22FF; font-weight: bold\">.</span>int64(<span style=\"color: #008000\">128</span>)), <span style=\"color: #BA2121\">&quot;float32&quot;</span>)):\n",
              "        T<span style=\"color: #AA22FF; font-weight: bold\">.</span>func_attr({<span style=\"color: #BA2121\">&quot;tir.noalias&quot;</span>: T<span style=\"color: #AA22FF; font-weight: bold\">.</span>bool(<span style=\"color: #008000; font-weight: bold\">True</span>)})\n",
              "        <span style=\"color: #007979; font-style: italic\"># with T.block(&quot;root&quot;):</span>\n",
              "        <span style=\"color: #008000; font-weight: bold\">for</span> ax0, ax1 <span style=\"color: #008000; font-weight: bold\">in</span> T<span style=\"color: #AA22FF; font-weight: bold\">.</span>grid(T<span style=\"color: #AA22FF; font-weight: bold\">.</span>int64(<span style=\"color: #008000\">1</span>), T<span style=\"color: #AA22FF; font-weight: bold\">.</span>int64(<span style=\"color: #008000\">128</span>)):\n",
              "            <span style=\"color: #008000; font-weight: bold\">with</span> T<span style=\"color: #AA22FF; font-weight: bold\">.</span>block(<span style=\"color: #BA2121\">&quot;T_add&quot;</span>):\n",
              "                v_ax0, v_ax1 <span style=\"color: #AA22FF; font-weight: bold\">=</span> T<span style=\"color: #AA22FF; font-weight: bold\">.</span>axis<span style=\"color: #AA22FF; font-weight: bold\">.</span>remap(<span style=\"color: #BA2121\">&quot;SS&quot;</span>, [ax0, ax1])\n",
              "                T<span style=\"color: #AA22FF; font-weight: bold\">.</span>reads(A[v_ax0, v_ax1], B[v_ax1])\n",
              "                T<span style=\"color: #AA22FF; font-weight: bold\">.</span>writes(T_add[v_ax0, v_ax1])\n",
              "                T_add[v_ax0, v_ax1] <span style=\"color: #AA22FF; font-weight: bold\">=</span> A[v_ax0, v_ax1] <span style=\"color: #AA22FF; font-weight: bold\">+</span> B[v_ax1]\n",
              "\n",
              "    <span style=\"color: #AA22FF\">@T</span><span style=\"color: #AA22FF; font-weight: bold\">.</span>prim_func\n",
              "    <span style=\"color: #008000; font-weight: bold\">def</span> <span style=\"color: #0000FF\">add1</span>(A: T<span style=\"color: #AA22FF; font-weight: bold\">.</span>Buffer((T<span style=\"color: #AA22FF; font-weight: bold\">.</span>int64(<span style=\"color: #008000\">1</span>), T<span style=\"color: #AA22FF; font-weight: bold\">.</span>int64(<span style=\"color: #008000\">10</span>)), <span style=\"color: #BA2121\">&quot;float32&quot;</span>), B: T<span style=\"color: #AA22FF; font-weight: bold\">.</span>Buffer((T<span style=\"color: #AA22FF; font-weight: bold\">.</span>int64(<span style=\"color: #008000\">10</span>),), <span style=\"color: #BA2121\">&quot;float32&quot;</span>), T_add: T<span style=\"color: #AA22FF; font-weight: bold\">.</span>Buffer((T<span style=\"color: #AA22FF; font-weight: bold\">.</span>int64(<span style=\"color: #008000\">1</span>), T<span style=\"color: #AA22FF; font-weight: bold\">.</span>int64(<span style=\"color: #008000\">10</span>)), <span style=\"color: #BA2121\">&quot;float32&quot;</span>)):\n",
              "        T<span style=\"color: #AA22FF; font-weight: bold\">.</span>func_attr({<span style=\"color: #BA2121\">&quot;tir.noalias&quot;</span>: T<span style=\"color: #AA22FF; font-weight: bold\">.</span>bool(<span style=\"color: #008000; font-weight: bold\">True</span>)})\n",
              "        <span style=\"color: #007979; font-style: italic\"># with T.block(&quot;root&quot;):</span>\n",
              "        <span style=\"color: #008000; font-weight: bold\">for</span> ax0, ax1 <span style=\"color: #008000; font-weight: bold\">in</span> T<span style=\"color: #AA22FF; font-weight: bold\">.</span>grid(T<span style=\"color: #AA22FF; font-weight: bold\">.</span>int64(<span style=\"color: #008000\">1</span>), T<span style=\"color: #AA22FF; font-weight: bold\">.</span>int64(<span style=\"color: #008000\">10</span>)):\n",
              "            <span style=\"color: #008000; font-weight: bold\">with</span> T<span style=\"color: #AA22FF; font-weight: bold\">.</span>block(<span style=\"color: #BA2121\">&quot;T_add&quot;</span>):\n",
              "                v_ax0, v_ax1 <span style=\"color: #AA22FF; font-weight: bold\">=</span> T<span style=\"color: #AA22FF; font-weight: bold\">.</span>axis<span style=\"color: #AA22FF; font-weight: bold\">.</span>remap(<span style=\"color: #BA2121\">&quot;SS&quot;</span>, [ax0, ax1])\n",
              "                T<span style=\"color: #AA22FF; font-weight: bold\">.</span>reads(A[v_ax0, v_ax1], B[v_ax1])\n",
              "                T<span style=\"color: #AA22FF; font-weight: bold\">.</span>writes(T_add[v_ax0, v_ax1])\n",
              "                T_add[v_ax0, v_ax1] <span style=\"color: #AA22FF; font-weight: bold\">=</span> A[v_ax0, v_ax1] <span style=\"color: #AA22FF; font-weight: bold\">+</span> B[v_ax1]\n",
              "\n",
              "    <span style=\"color: #AA22FF\">@T</span><span style=\"color: #AA22FF; font-weight: bold\">.</span>prim_func\n",
              "    <span style=\"color: #008000; font-weight: bold\">def</span> <span style=\"color: #0000FF\">dense</span>(A: T<span style=\"color: #AA22FF; font-weight: bold\">.</span>Buffer((T<span style=\"color: #AA22FF; font-weight: bold\">.</span>int64(<span style=\"color: #008000\">1</span>), T<span style=\"color: #AA22FF; font-weight: bold\">.</span>int64(<span style=\"color: #008000\">784</span>)), <span style=\"color: #BA2121\">&quot;float32&quot;</span>), B: T<span style=\"color: #AA22FF; font-weight: bold\">.</span>Buffer((T<span style=\"color: #AA22FF; font-weight: bold\">.</span>int64(<span style=\"color: #008000\">128</span>), T<span style=\"color: #AA22FF; font-weight: bold\">.</span>int64(<span style=\"color: #008000\">784</span>)), <span style=\"color: #BA2121\">&quot;float32&quot;</span>), T_matmul_NT: T<span style=\"color: #AA22FF; font-weight: bold\">.</span>Buffer((T<span style=\"color: #AA22FF; font-weight: bold\">.</span>int64(<span style=\"color: #008000\">1</span>), T<span style=\"color: #AA22FF; font-weight: bold\">.</span>int64(<span style=\"color: #008000\">128</span>)), <span style=\"color: #BA2121\">&quot;float32&quot;</span>)):\n",
              "        T<span style=\"color: #AA22FF; font-weight: bold\">.</span>func_attr({<span style=\"color: #BA2121\">&quot;layout_free_buffers&quot;</span>: [<span style=\"color: #008000\">1</span>], <span style=\"color: #BA2121\">&quot;tir.noalias&quot;</span>: T<span style=\"color: #AA22FF; font-weight: bold\">.</span>bool(<span style=\"color: #008000; font-weight: bold\">True</span>)})\n",
              "        <span style=\"color: #007979; font-style: italic\"># with T.block(&quot;root&quot;):</span>\n",
              "        <span style=\"color: #008000; font-weight: bold\">for</span> i, j, k <span style=\"color: #008000; font-weight: bold\">in</span> T<span style=\"color: #AA22FF; font-weight: bold\">.</span>grid(T<span style=\"color: #AA22FF; font-weight: bold\">.</span>int64(<span style=\"color: #008000\">1</span>), T<span style=\"color: #AA22FF; font-weight: bold\">.</span>int64(<span style=\"color: #008000\">128</span>), T<span style=\"color: #AA22FF; font-weight: bold\">.</span>int64(<span style=\"color: #008000\">784</span>)):\n",
              "            <span style=\"color: #008000; font-weight: bold\">with</span> T<span style=\"color: #AA22FF; font-weight: bold\">.</span>block(<span style=\"color: #BA2121\">&quot;T_matmul_NT&quot;</span>):\n",
              "                v_i, v_j, v_k <span style=\"color: #AA22FF; font-weight: bold\">=</span> T<span style=\"color: #AA22FF; font-weight: bold\">.</span>axis<span style=\"color: #AA22FF; font-weight: bold\">.</span>remap(<span style=\"color: #BA2121\">&quot;SSR&quot;</span>, [i, j, k])\n",
              "                T<span style=\"color: #AA22FF; font-weight: bold\">.</span>reads(A[v_i, v_k], B[v_j, v_k])\n",
              "                T<span style=\"color: #AA22FF; font-weight: bold\">.</span>writes(T_matmul_NT[v_i, v_j])\n",
              "                <span style=\"color: #008000; font-weight: bold\">with</span> T<span style=\"color: #AA22FF; font-weight: bold\">.</span>init():\n",
              "                    T_matmul_NT[v_i, v_j] <span style=\"color: #AA22FF; font-weight: bold\">=</span> T<span style=\"color: #AA22FF; font-weight: bold\">.</span>float32(<span style=\"color: #008000\">0</span>)\n",
              "                T_matmul_NT[v_i, v_j] <span style=\"color: #AA22FF; font-weight: bold\">=</span> T_matmul_NT[v_i, v_j] <span style=\"color: #AA22FF; font-weight: bold\">+</span> A[v_i, v_k] <span style=\"color: #AA22FF; font-weight: bold\">*</span> B[v_j, v_k]\n",
              "\n",
              "    <span style=\"color: #AA22FF\">@T</span><span style=\"color: #AA22FF; font-weight: bold\">.</span>prim_func\n",
              "    <span style=\"color: #008000; font-weight: bold\">def</span> <span style=\"color: #0000FF\">dense1</span>(A: T<span style=\"color: #AA22FF; font-weight: bold\">.</span>Buffer((T<span style=\"color: #AA22FF; font-weight: bold\">.</span>int64(<span style=\"color: #008000\">1</span>), T<span style=\"color: #AA22FF; font-weight: bold\">.</span>int64(<span style=\"color: #008000\">128</span>)), <span style=\"color: #BA2121\">&quot;float32&quot;</span>), B: T<span style=\"color: #AA22FF; font-weight: bold\">.</span>Buffer((T<span style=\"color: #AA22FF; font-weight: bold\">.</span>int64(<span style=\"color: #008000\">10</span>), T<span style=\"color: #AA22FF; font-weight: bold\">.</span>int64(<span style=\"color: #008000\">128</span>)), <span style=\"color: #BA2121\">&quot;float32&quot;</span>), T_matmul_NT: T<span style=\"color: #AA22FF; font-weight: bold\">.</span>Buffer((T<span style=\"color: #AA22FF; font-weight: bold\">.</span>int64(<span style=\"color: #008000\">1</span>), T<span style=\"color: #AA22FF; font-weight: bold\">.</span>int64(<span style=\"color: #008000\">10</span>)), <span style=\"color: #BA2121\">&quot;float32&quot;</span>)):\n",
              "        T<span style=\"color: #AA22FF; font-weight: bold\">.</span>func_attr({<span style=\"color: #BA2121\">&quot;layout_free_buffers&quot;</span>: [<span style=\"color: #008000\">1</span>], <span style=\"color: #BA2121\">&quot;tir.noalias&quot;</span>: T<span style=\"color: #AA22FF; font-weight: bold\">.</span>bool(<span style=\"color: #008000; font-weight: bold\">True</span>)})\n",
              "        <span style=\"color: #007979; font-style: italic\"># with T.block(&quot;root&quot;):</span>\n",
              "        <span style=\"color: #008000; font-weight: bold\">for</span> i, j, k <span style=\"color: #008000; font-weight: bold\">in</span> T<span style=\"color: #AA22FF; font-weight: bold\">.</span>grid(T<span style=\"color: #AA22FF; font-weight: bold\">.</span>int64(<span style=\"color: #008000\">1</span>), T<span style=\"color: #AA22FF; font-weight: bold\">.</span>int64(<span style=\"color: #008000\">10</span>), T<span style=\"color: #AA22FF; font-weight: bold\">.</span>int64(<span style=\"color: #008000\">128</span>)):\n",
              "            <span style=\"color: #008000; font-weight: bold\">with</span> T<span style=\"color: #AA22FF; font-weight: bold\">.</span>block(<span style=\"color: #BA2121\">&quot;T_matmul_NT&quot;</span>):\n",
              "                v_i, v_j, v_k <span style=\"color: #AA22FF; font-weight: bold\">=</span> T<span style=\"color: #AA22FF; font-weight: bold\">.</span>axis<span style=\"color: #AA22FF; font-weight: bold\">.</span>remap(<span style=\"color: #BA2121\">&quot;SSR&quot;</span>, [i, j, k])\n",
              "                T<span style=\"color: #AA22FF; font-weight: bold\">.</span>reads(A[v_i, v_k], B[v_j, v_k])\n",
              "                T<span style=\"color: #AA22FF; font-weight: bold\">.</span>writes(T_matmul_NT[v_i, v_j])\n",
              "                <span style=\"color: #008000; font-weight: bold\">with</span> T<span style=\"color: #AA22FF; font-weight: bold\">.</span>init():\n",
              "                    T_matmul_NT[v_i, v_j] <span style=\"color: #AA22FF; font-weight: bold\">=</span> T<span style=\"color: #AA22FF; font-weight: bold\">.</span>float32(<span style=\"color: #008000\">0</span>)\n",
              "                T_matmul_NT[v_i, v_j] <span style=\"color: #AA22FF; font-weight: bold\">=</span> T_matmul_NT[v_i, v_j] <span style=\"color: #AA22FF; font-weight: bold\">+</span> A[v_i, v_k] <span style=\"color: #AA22FF; font-weight: bold\">*</span> B[v_j, v_k]\n",
              "\n",
              "    <span style=\"color: #AA22FF\">@T</span><span style=\"color: #AA22FF; font-weight: bold\">.</span>prim_func\n",
              "    <span style=\"color: #008000; font-weight: bold\">def</span> <span style=\"color: #0000FF\">te_relu</span>(A: T<span style=\"color: #AA22FF; font-weight: bold\">.</span>Buffer((T<span style=\"color: #AA22FF; font-weight: bold\">.</span>int64(<span style=\"color: #008000\">1</span>), T<span style=\"color: #AA22FF; font-weight: bold\">.</span>int64(<span style=\"color: #008000\">128</span>)), <span style=\"color: #BA2121\">&quot;float32&quot;</span>), relu: T<span style=\"color: #AA22FF; font-weight: bold\">.</span>Buffer((T<span style=\"color: #AA22FF; font-weight: bold\">.</span>int64(<span style=\"color: #008000\">1</span>), T<span style=\"color: #AA22FF; font-weight: bold\">.</span>int64(<span style=\"color: #008000\">128</span>)), <span style=\"color: #BA2121\">&quot;float32&quot;</span>)):\n",
              "        T<span style=\"color: #AA22FF; font-weight: bold\">.</span>func_attr({<span style=\"color: #BA2121\">&quot;tir.noalias&quot;</span>: T<span style=\"color: #AA22FF; font-weight: bold\">.</span>bool(<span style=\"color: #008000; font-weight: bold\">True</span>)})\n",
              "        <span style=\"color: #007979; font-style: italic\"># with T.block(&quot;root&quot;):</span>\n",
              "        <span style=\"color: #008000; font-weight: bold\">for</span> i0, i1 <span style=\"color: #008000; font-weight: bold\">in</span> T<span style=\"color: #AA22FF; font-weight: bold\">.</span>grid(T<span style=\"color: #AA22FF; font-weight: bold\">.</span>int64(<span style=\"color: #008000\">1</span>), T<span style=\"color: #AA22FF; font-weight: bold\">.</span>int64(<span style=\"color: #008000\">128</span>)):\n",
              "            <span style=\"color: #008000; font-weight: bold\">with</span> T<span style=\"color: #AA22FF; font-weight: bold\">.</span>block(<span style=\"color: #BA2121\">&quot;relu&quot;</span>):\n",
              "                v_i0, v_i1 <span style=\"color: #AA22FF; font-weight: bold\">=</span> T<span style=\"color: #AA22FF; font-weight: bold\">.</span>axis<span style=\"color: #AA22FF; font-weight: bold\">.</span>remap(<span style=\"color: #BA2121\">&quot;SS&quot;</span>, [i0, i1])\n",
              "                T<span style=\"color: #AA22FF; font-weight: bold\">.</span>reads(A[v_i0, v_i1])\n",
              "                T<span style=\"color: #AA22FF; font-weight: bold\">.</span>writes(relu[v_i0, v_i1])\n",
              "                relu[v_i0, v_i1] <span style=\"color: #AA22FF; font-weight: bold\">=</span> T<span style=\"color: #AA22FF; font-weight: bold\">.</span>max(A[v_i0, v_i1], T<span style=\"color: #AA22FF; font-weight: bold\">.</span>float32(<span style=\"color: #008000\">0</span>))\n",
              "\n",
              "    <span style=\"color: #AA22FF\">@R</span><span style=\"color: #AA22FF; font-weight: bold\">.</span>function\n",
              "    <span style=\"color: #008000; font-weight: bold\">def</span> <span style=\"color: #0000FF\">main</span>(x: R<span style=\"color: #AA22FF; font-weight: bold\">.</span>Tensor((<span style=\"color: #008000\">1</span>, <span style=\"color: #008000\">784</span>), dtype<span style=\"color: #AA22FF; font-weight: bold\">=</span><span style=\"color: #BA2121\">&quot;float32&quot;</span>)) <span style=\"color: #AA22FF; font-weight: bold\">-&gt;</span> R<span style=\"color: #AA22FF; font-weight: bold\">.</span>Tensor((<span style=\"color: #008000\">1</span>, <span style=\"color: #008000\">10</span>), dtype<span style=\"color: #AA22FF; font-weight: bold\">=</span><span style=\"color: #BA2121\">&quot;float32&quot;</span>):\n",
              "        cls <span style=\"color: #AA22FF; font-weight: bold\">=</span> Module\n",
              "        <span style=\"color: #008000; font-weight: bold\">with</span> R<span style=\"color: #AA22FF; font-weight: bold\">.</span>dataflow():\n",
              "            lv <span style=\"color: #AA22FF; font-weight: bold\">=</span> R<span style=\"color: #AA22FF; font-weight: bold\">.</span>call_tir(cls<span style=\"color: #AA22FF; font-weight: bold\">.</span>dense, (x, metadata[<span style=\"color: #BA2121\">&quot;relax.expr.Constant&quot;</span>][<span style=\"color: #008000\">0</span>]), out_sinfo<span style=\"color: #AA22FF; font-weight: bold\">=</span>R<span style=\"color: #AA22FF; font-weight: bold\">.</span>Tensor((<span style=\"color: #008000\">1</span>, <span style=\"color: #008000\">128</span>), dtype<span style=\"color: #AA22FF; font-weight: bold\">=</span><span style=\"color: #BA2121\">&quot;float32&quot;</span>))\n",
              "            lv1 <span style=\"color: #AA22FF; font-weight: bold\">=</span> R<span style=\"color: #AA22FF; font-weight: bold\">.</span>call_tir(cls<span style=\"color: #AA22FF; font-weight: bold\">.</span>add, (lv, metadata[<span style=\"color: #BA2121\">&quot;relax.expr.Constant&quot;</span>][<span style=\"color: #008000\">1</span>]), out_sinfo<span style=\"color: #AA22FF; font-weight: bold\">=</span>R<span style=\"color: #AA22FF; font-weight: bold\">.</span>Tensor((<span style=\"color: #008000\">1</span>, <span style=\"color: #008000\">128</span>), dtype<span style=\"color: #AA22FF; font-weight: bold\">=</span><span style=\"color: #BA2121\">&quot;float32&quot;</span>))\n",
              "            lv2 <span style=\"color: #AA22FF; font-weight: bold\">=</span> R<span style=\"color: #AA22FF; font-weight: bold\">.</span>call_tir(cls<span style=\"color: #AA22FF; font-weight: bold\">.</span>te_relu, (lv1,), out_sinfo<span style=\"color: #AA22FF; font-weight: bold\">=</span>R<span style=\"color: #AA22FF; font-weight: bold\">.</span>Tensor((<span style=\"color: #008000\">1</span>, <span style=\"color: #008000\">128</span>), dtype<span style=\"color: #AA22FF; font-weight: bold\">=</span><span style=\"color: #BA2121\">&quot;float32&quot;</span>))\n",
              "            lv3 <span style=\"color: #AA22FF; font-weight: bold\">=</span> R<span style=\"color: #AA22FF; font-weight: bold\">.</span>call_tir(cls<span style=\"color: #AA22FF; font-weight: bold\">.</span>dense1, (lv2, metadata[<span style=\"color: #BA2121\">&quot;relax.expr.Constant&quot;</span>][<span style=\"color: #008000\">2</span>]), out_sinfo<span style=\"color: #AA22FF; font-weight: bold\">=</span>R<span style=\"color: #AA22FF; font-weight: bold\">.</span>Tensor((<span style=\"color: #008000\">1</span>, <span style=\"color: #008000\">10</span>), dtype<span style=\"color: #AA22FF; font-weight: bold\">=</span><span style=\"color: #BA2121\">&quot;float32&quot;</span>))\n",
              "            lv4 <span style=\"color: #AA22FF; font-weight: bold\">=</span> R<span style=\"color: #AA22FF; font-weight: bold\">.</span>call_tir(cls<span style=\"color: #AA22FF; font-weight: bold\">.</span>add1, (lv3, metadata[<span style=\"color: #BA2121\">&quot;relax.expr.Constant&quot;</span>][<span style=\"color: #008000\">3</span>]), out_sinfo<span style=\"color: #AA22FF; font-weight: bold\">=</span>R<span style=\"color: #AA22FF; font-weight: bold\">.</span>Tensor((<span style=\"color: #008000\">1</span>, <span style=\"color: #008000\">10</span>), dtype<span style=\"color: #AA22FF; font-weight: bold\">=</span><span style=\"color: #BA2121\">&quot;float32&quot;</span>))\n",
              "            gv: R<span style=\"color: #AA22FF; font-weight: bold\">.</span>Tensor((<span style=\"color: #008000\">1</span>, <span style=\"color: #008000\">10</span>), dtype<span style=\"color: #AA22FF; font-weight: bold\">=</span><span style=\"color: #BA2121\">&quot;float32&quot;</span>) <span style=\"color: #AA22FF; font-weight: bold\">=</span> lv4\n",
              "            R<span style=\"color: #AA22FF; font-weight: bold\">.</span>output(gv)\n",
              "        <span style=\"color: #008000; font-weight: bold\">return</span> gv\n",
              "\n",
              "<span style=\"color: #007979; font-style: italic\"># Metadata omitted. Use show_meta=True in script() method to show it.</span>\n",
              "</pre></div>\n"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# build and run\n",
        "ex = relax.build(MLPModule, target='llvm')\n",
        "vm = relax.VirtualMachine(ex, tvm.cpu())\n",
        "data_nd = tvm.nd.array(img.reshape(1, 784))\n",
        "\n",
        "nd_res = vm[\"main\"](data_nd)\n",
        "\n",
        "pred_kind = np.argmax(nd_res.numpy(), axis=1)\n",
        "print(\"tvm mlp module prediction:\", class_names[pred_kind[0]])\n",
        "# success prediction"
      ],
      "metadata": {
        "id": "b4IvzRC8ibxS",
        "outputId": "75513969-a860-4b88-a83f-101134ab47bf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tvm mlp module prediction: T-shirt/top\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Translate to high-level primitives\n",
        "\n",
        "instead of translating directly to TensorIR module, we can translate the pytorch function to some high-level built-in primitive operators.\n",
        "\n",
        "### how to?\n",
        "simply change the way we map each function!"
      ],
      "metadata": {
        "id": "dQ_BuDpHjGzR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def map_nn_relu_op(bb, node_map, node, nn_mod):\n",
        "    A = node_map[node.args[0]]\n",
        "    return bb.emit(relax.op.nn.relu(A))\n",
        "\n",
        "def map_nn_linear_op(bb, node_map, node, nn_mod):\n",
        "    x = node_map[node.args[0]]\n",
        "    w = map_param(nn_mod.weight)\n",
        "    b = map_param(nn_mod.bias)\n",
        "    return bb.emit(relax.op.linear(x, w, b))\n",
        "\n",
        "# exact call as above (copied over here)\n",
        "MLPModuleHighLevel = from_fx(\n",
        "    fx.symbolic_trace(mlp_model),\n",
        "    input_shapes = [(1, 784)],\n",
        "    call_function_map={},\n",
        "    call_module_map={\n",
        "        torch.nn.Linear: map_nn_linear_op,\n",
        "        torch.nn.ReLU: map_nn_relu_op, # use map_op instead!!!\n",
        "    },\n",
        ")\n",
        "\n",
        "MLPModuleHighLevel.show()"
      ],
      "metadata": {
        "id": "AAGrBqLYjYcq",
        "outputId": "4067c87c-6a70-45cb-ea87-e36e0c60a58d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 436
        }
      },
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/tvm/script/highlight.py:117: UserWarning: No module named 'black'\n",
            "To print formatted TVM script, please install the formatter 'Black':\n",
            "/usr/bin/python3 -m pip install \"black==22.3.0\" --upgrade --user\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<div class=\"highlight\" style=\"background: \"><pre style=\"line-height: 125%;\"><span></span><span style=\"color: #007979; font-style: italic\"># from tvm.script import ir as I</span>\n",
              "<span style=\"color: #007979; font-style: italic\"># from tvm.script import relax as R</span>\n",
              "\n",
              "<span style=\"color: #AA22FF\">@I</span><span style=\"color: #AA22FF; font-weight: bold\">.</span>ir_module\n",
              "<span style=\"color: #008000; font-weight: bold\">class</span> <span style=\"color: #0000FF; font-weight: bold\">Module</span>:\n",
              "    <span style=\"color: #AA22FF\">@R</span><span style=\"color: #AA22FF; font-weight: bold\">.</span>function\n",
              "    <span style=\"color: #008000; font-weight: bold\">def</span> <span style=\"color: #0000FF\">main</span>(x: R<span style=\"color: #AA22FF; font-weight: bold\">.</span>Tensor((<span style=\"color: #008000\">1</span>, <span style=\"color: #008000\">784</span>), dtype<span style=\"color: #AA22FF; font-weight: bold\">=</span><span style=\"color: #BA2121\">&quot;float32&quot;</span>)) <span style=\"color: #AA22FF; font-weight: bold\">-&gt;</span> R<span style=\"color: #AA22FF; font-weight: bold\">.</span>Tensor((<span style=\"color: #008000\">1</span>, <span style=\"color: #008000\">10</span>), dtype<span style=\"color: #AA22FF; font-weight: bold\">=</span><span style=\"color: #BA2121\">&quot;float32&quot;</span>):\n",
              "        <span style=\"color: #008000; font-weight: bold\">with</span> R<span style=\"color: #AA22FF; font-weight: bold\">.</span>dataflow():\n",
              "            lv: R<span style=\"color: #AA22FF; font-weight: bold\">.</span>Tensor((<span style=\"color: #008000\">784</span>, <span style=\"color: #008000\">128</span>), dtype<span style=\"color: #AA22FF; font-weight: bold\">=</span><span style=\"color: #BA2121\">&quot;float32&quot;</span>) <span style=\"color: #AA22FF; font-weight: bold\">=</span> R<span style=\"color: #AA22FF; font-weight: bold\">.</span>permute_dims(metadata[<span style=\"color: #BA2121\">&quot;relax.expr.Constant&quot;</span>][<span style=\"color: #008000\">0</span>], axes<span style=\"color: #AA22FF; font-weight: bold\">=</span><span style=\"color: #008000; font-weight: bold\">None</span>)\n",
              "            lv1: R<span style=\"color: #AA22FF; font-weight: bold\">.</span>Tensor((<span style=\"color: #008000\">1</span>, <span style=\"color: #008000\">128</span>), dtype<span style=\"color: #AA22FF; font-weight: bold\">=</span><span style=\"color: #BA2121\">&quot;float32&quot;</span>) <span style=\"color: #AA22FF; font-weight: bold\">=</span> R<span style=\"color: #AA22FF; font-weight: bold\">.</span>matmul(x, lv, out_dtype<span style=\"color: #AA22FF; font-weight: bold\">=</span><span style=\"color: #BA2121\">&quot;void&quot;</span>)\n",
              "            lv2: R<span style=\"color: #AA22FF; font-weight: bold\">.</span>Tensor((<span style=\"color: #008000\">1</span>, <span style=\"color: #008000\">128</span>), dtype<span style=\"color: #AA22FF; font-weight: bold\">=</span><span style=\"color: #BA2121\">&quot;float32&quot;</span>) <span style=\"color: #AA22FF; font-weight: bold\">=</span> R<span style=\"color: #AA22FF; font-weight: bold\">.</span>add(lv1, metadata[<span style=\"color: #BA2121\">&quot;relax.expr.Constant&quot;</span>][<span style=\"color: #008000\">1</span>])\n",
              "            lv3: R<span style=\"color: #AA22FF; font-weight: bold\">.</span>Tensor((<span style=\"color: #008000\">1</span>, <span style=\"color: #008000\">128</span>), dtype<span style=\"color: #AA22FF; font-weight: bold\">=</span><span style=\"color: #BA2121\">&quot;float32&quot;</span>) <span style=\"color: #AA22FF; font-weight: bold\">=</span> R<span style=\"color: #AA22FF; font-weight: bold\">.</span>nn<span style=\"color: #AA22FF; font-weight: bold\">.</span>relu(lv2)\n",
              "            lv4: R<span style=\"color: #AA22FF; font-weight: bold\">.</span>Tensor((<span style=\"color: #008000\">128</span>, <span style=\"color: #008000\">10</span>), dtype<span style=\"color: #AA22FF; font-weight: bold\">=</span><span style=\"color: #BA2121\">&quot;float32&quot;</span>) <span style=\"color: #AA22FF; font-weight: bold\">=</span> R<span style=\"color: #AA22FF; font-weight: bold\">.</span>permute_dims(metadata[<span style=\"color: #BA2121\">&quot;relax.expr.Constant&quot;</span>][<span style=\"color: #008000\">2</span>], axes<span style=\"color: #AA22FF; font-weight: bold\">=</span><span style=\"color: #008000; font-weight: bold\">None</span>)\n",
              "            lv5: R<span style=\"color: #AA22FF; font-weight: bold\">.</span>Tensor((<span style=\"color: #008000\">1</span>, <span style=\"color: #008000\">10</span>), dtype<span style=\"color: #AA22FF; font-weight: bold\">=</span><span style=\"color: #BA2121\">&quot;float32&quot;</span>) <span style=\"color: #AA22FF; font-weight: bold\">=</span> R<span style=\"color: #AA22FF; font-weight: bold\">.</span>matmul(lv3, lv4, out_dtype<span style=\"color: #AA22FF; font-weight: bold\">=</span><span style=\"color: #BA2121\">&quot;void&quot;</span>)\n",
              "            lv6: R<span style=\"color: #AA22FF; font-weight: bold\">.</span>Tensor((<span style=\"color: #008000\">1</span>, <span style=\"color: #008000\">10</span>), dtype<span style=\"color: #AA22FF; font-weight: bold\">=</span><span style=\"color: #BA2121\">&quot;float32&quot;</span>) <span style=\"color: #AA22FF; font-weight: bold\">=</span> R<span style=\"color: #AA22FF; font-weight: bold\">.</span>add(lv5, metadata[<span style=\"color: #BA2121\">&quot;relax.expr.Constant&quot;</span>][<span style=\"color: #008000\">3</span>])\n",
              "            gv: R<span style=\"color: #AA22FF; font-weight: bold\">.</span>Tensor((<span style=\"color: #008000\">1</span>, <span style=\"color: #008000\">10</span>), dtype<span style=\"color: #AA22FF; font-weight: bold\">=</span><span style=\"color: #BA2121\">&quot;float32&quot;</span>) <span style=\"color: #AA22FF; font-weight: bold\">=</span> lv6\n",
              "            R<span style=\"color: #AA22FF; font-weight: bold\">.</span>output(gv)\n",
              "        <span style=\"color: #008000; font-weight: bold\">return</span> gv\n",
              "\n",
              "<span style=\"color: #007979; font-style: italic\"># Metadata omitted. Use show_meta=True in script() method to show it.</span>\n",
              "</pre></div>\n"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "j2UY8XUmkj67"
      },
      "execution_count": 47,
      "outputs": []
    }
  ]
}