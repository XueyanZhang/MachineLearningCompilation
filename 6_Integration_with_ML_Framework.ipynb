{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNbHMnQxrPSCJDvDUf38Znz",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/XueyanZhang/MachineLearningCompilation/blob/master/6_Integration_with_ML_Framework.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eM_tP5o9eg24"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Integration with Machine Learning Frameworks"
      ],
      "metadata": {
        "id": "zrSj4-I1eq_M"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!python3 -m  pip install mlc-ai-nightly -f https://mlc.ai/wheels\n",
        "\n",
        "import numpy as np\n",
        "import tvm\n",
        "from tvm import relax\n",
        "from tvm.ir.module import IRModule\n",
        "from tvm.script import relax as R\n",
        "from tvm.script import tir as T\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch import fx\n",
        "from torch.nn import functional as F"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CFoZkvdkesQ-",
        "outputId": "a316d260-e5f1-46c2-a7af-e04834976142"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Looking in links: https://mlc.ai/wheels\n",
            "Collecting mlc-ai-nightly\n",
            "  Downloading https://github.com/mlc-ai/utils/releases/download/v0.9.dev0/mlc_ai_nightly-0.12.dev878%2Bgd65d311af-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (52.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m52.1/52.1 MB\u001b[0m \u001b[31m10.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: attrs in /usr/local/lib/python3.10/dist-packages (from mlc-ai-nightly) (23.1.0)\n",
            "Requirement already satisfied: cloudpickle in /usr/local/lib/python3.10/dist-packages (from mlc-ai-nightly) (2.2.1)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.10/dist-packages (from mlc-ai-nightly) (4.4.2)\n",
            "Requirement already satisfied: numpy<=1.23 in /usr/local/lib/python3.10/dist-packages (from mlc-ai-nightly) (1.22.4)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from mlc-ai-nightly) (5.9.5)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from mlc-ai-nightly) (1.10.1)\n",
            "Requirement already satisfied: tornado in /usr/local/lib/python3.10/dist-packages (from mlc-ai-nightly) (6.2)\n",
            "Installing collected packages: mlc-ai-nightly\n",
            "Successfully installed mlc-ai-nightly-0.12.dev878+gd65d311af\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Build IRModule via Builder\n",
        "\n",
        "past IRModules was written mannual in TVMScript.\n",
        "\n",
        "it doesn't meet the demand for large systems.\n",
        "\n",
        "need a way to construct IRModule programmatically."
      ],
      "metadata": {
        "id": "B4VnhVBee6RV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Tensor Expression\n",
        "\n",
        "Tensor Expression for TensorIR Creation"
      ],
      "metadata": {
        "id": "kC80RTWWfXW7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tvm import te\n",
        "\n",
        "# create input\n",
        "f32 = \"float32\"\n",
        "A = te.placeholder((128, 128), name=\"A\", dtype=\"float32\")\n",
        "B = te.placeholder((128, 128), name=\"B\", dtype=\"float32\")\n",
        "print(type(A))\n",
        "print(A.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "am8PqFpaeyku",
        "outputId": "b8c08bbc-74a1-4fc7-ad6f-e5d9a4cc2643"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'tvm.te.tensor.Tensor'>\n",
            "[128, 128]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# define computation\n",
        "def te_matmul(A: te.Tensor, B: te.Tensor) -> te.Tensor:\n",
        "    assert A.shape[1] == B.shape[0]\n",
        "    m = A.shape[0]\n",
        "    n = B.shape[1]\n",
        "    k = te.reduce_axis((0, A.shape[1]), name='k')\n",
        "    return te.compute((m, n), lambda i, j: te.sum(A[i, k] * B[k, j], axis=k), name=\"matmul\")"
      ],
      "metadata": {
        "id": "KCyRaJ8Df2D_"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# create result\n",
        "C = te_matmul(A, B)\n",
        "print(C)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EI3j9AZBg8Jv",
        "outputId": "c18864c4-575f-44dd-ba4e-8f5f6b9e281c"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tensor(shape=[128, 128], op.name=matmul)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# create TensorIR function\n",
        "te.create_prim_func([A, B, C]).show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 331
        },
        "id": "zG_a1NNfhRRe",
        "outputId": "ceaf3d58-e012-4049-edda-4214783cda4e"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/tvm/script/highlight.py:117: UserWarning: No module named 'black'\n",
            "To print formatted TVM script, please install the formatter 'Black':\n",
            "/usr/bin/python3 -m pip install \"black==22.3.0\" --upgrade --user\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<div class=\"highlight\" style=\"background: \"><pre style=\"line-height: 125%;\"><span></span><span style=\"color: #007979; font-style: italic\"># from tvm.script import tir as T</span>\n",
              "\n",
              "<span style=\"color: #AA22FF\">@T</span><span style=\"color: #AA22FF; font-weight: bold\">.</span>prim_func\n",
              "<span style=\"color: #008000; font-weight: bold\">def</span> <span style=\"color: #0000FF\">main</span>(A: T<span style=\"color: #AA22FF; font-weight: bold\">.</span>Buffer((<span style=\"color: #008000\">128</span>, <span style=\"color: #008000\">128</span>), <span style=\"color: #BA2121\">&quot;float32&quot;</span>), B: T<span style=\"color: #AA22FF; font-weight: bold\">.</span>Buffer((<span style=\"color: #008000\">128</span>, <span style=\"color: #008000\">128</span>), <span style=\"color: #BA2121\">&quot;float32&quot;</span>), matmul: T<span style=\"color: #AA22FF; font-weight: bold\">.</span>Buffer((<span style=\"color: #008000\">128</span>, <span style=\"color: #008000\">128</span>), <span style=\"color: #BA2121\">&quot;float32&quot;</span>)):\n",
              "    T<span style=\"color: #AA22FF; font-weight: bold\">.</span>func_attr({<span style=\"color: #BA2121\">&quot;global_symbol&quot;</span>: <span style=\"color: #BA2121\">&quot;main&quot;</span>, <span style=\"color: #BA2121\">&quot;tir.noalias&quot;</span>: T<span style=\"color: #AA22FF; font-weight: bold\">.</span>bool(<span style=\"color: #008000; font-weight: bold\">True</span>)})\n",
              "    <span style=\"color: #007979; font-style: italic\"># with T.block(&quot;root&quot;):</span>\n",
              "    <span style=\"color: #008000; font-weight: bold\">for</span> i, j, k <span style=\"color: #008000; font-weight: bold\">in</span> T<span style=\"color: #AA22FF; font-weight: bold\">.</span>grid(<span style=\"color: #008000\">128</span>, <span style=\"color: #008000\">128</span>, <span style=\"color: #008000\">128</span>):\n",
              "        <span style=\"color: #008000; font-weight: bold\">with</span> T<span style=\"color: #AA22FF; font-weight: bold\">.</span>block(<span style=\"color: #BA2121\">&quot;matmul&quot;</span>):\n",
              "            v_i, v_j, v_k <span style=\"color: #AA22FF; font-weight: bold\">=</span> T<span style=\"color: #AA22FF; font-weight: bold\">.</span>axis<span style=\"color: #AA22FF; font-weight: bold\">.</span>remap(<span style=\"color: #BA2121\">&quot;SSR&quot;</span>, [i, j, k])\n",
              "            T<span style=\"color: #AA22FF; font-weight: bold\">.</span>reads(A[v_i, v_k], B[v_k, v_j])\n",
              "            T<span style=\"color: #AA22FF; font-weight: bold\">.</span>writes(matmul[v_i, v_j])\n",
              "            <span style=\"color: #008000; font-weight: bold\">with</span> T<span style=\"color: #AA22FF; font-weight: bold\">.</span>init():\n",
              "                matmul[v_i, v_j] <span style=\"color: #AA22FF; font-weight: bold\">=</span> T<span style=\"color: #AA22FF; font-weight: bold\">.</span>float32(<span style=\"color: #008000\">0</span>)\n",
              "            matmul[v_i, v_j] <span style=\"color: #AA22FF; font-weight: bold\">=</span> matmul[v_i, v_j] <span style=\"color: #AA22FF; font-weight: bold\">+</span> A[v_i, v_k] <span style=\"color: #AA22FF; font-weight: bold\">*</span> B[v_k, v_j]\n",
              "</pre></div>\n"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# create relu func\n",
        "def te_relu(A: te.Tensor) -> te.Tensor:\n",
        "    return te.compute(A.shape, lambda *i: te.max(A(*i), 0), name=\"relu\")"
      ],
      "metadata": {
        "id": "Td_nmPULhph2"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "the `*i` represents arbitrary shape index. here are some examples:"
      ],
      "metadata": {
        "id": "qvAPFBYciREl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 1D input\n",
        "X1 = te.placeholder((10, ), dtype=f32, name='X1')\n",
        "Y1 = te_relu(X1)\n",
        "te.create_prim_func([X1, Y1])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HqHklnzYiO6v",
        "outputId": "e8093351-f593-4efd-9880-70298a7e055b"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "# from tvm.script import tir as T\n",
              "\n",
              "@T.prim_func\n",
              "def main(X1: T.Buffer((10,), \"float32\"), relu: T.Buffer((10,), \"float32\")):\n",
              "    T.func_attr({\"global_symbol\": \"main\", \"tir.noalias\": T.bool(True)})\n",
              "    # with T.block(\"root\"):\n",
              "    for i0 in range(10):\n",
              "        with T.block(\"relu\"):\n",
              "            v_i0 = T.axis.spatial(10, i0)\n",
              "            T.reads(X1[v_i0])\n",
              "            T.writes(relu[v_i0])\n",
              "            relu[v_i0] = T.max(X1[v_i0], T.float32(0))"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 2D input\n",
        "X2 = te.placeholder((10, 10), dtype=f32, name='X2')\n",
        "Y2 = te_relu(X2)\n",
        "te.create_prim_func([X2, Y2])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2KTtfnt3irR9",
        "outputId": "d8d93d39-f517-4978-bf58-676862a9cf42"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "# from tvm.script import tir as T\n",
              "\n",
              "@T.prim_func\n",
              "def main(X2: T.Buffer((10, 10), \"float32\"), relu: T.Buffer((10, 10), \"float32\")):\n",
              "    T.func_attr({\"global_symbol\": \"main\", \"tir.noalias\": T.bool(True)})\n",
              "    # with T.block(\"root\"):\n",
              "    for i0, i1 in T.grid(10, 10):\n",
              "        with T.block(\"relu\"):\n",
              "            v_i0, v_i1 = T.axis.remap(\"SS\", [i0, i1])\n",
              "            T.reads(X2[v_i0, v_i1])\n",
              "            T.writes(relu[v_i0, v_i1])\n",
              "            relu[v_i0, v_i1] = T.max(X2[v_i0, v_i1], T.float32(0))"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## fuse / fusion "
      ],
      "metadata": {
        "id": "34ozR2-Li5rq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# fuse matmul w/ relu\n",
        "C = te_matmul(A, B)\n",
        "D = te_relu(C)\n",
        "\n",
        "te.create_prim_func([A, B, D]).show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 454
        },
        "id": "MazeFDKJjA9G",
        "outputId": "dec313a9-574b-4d41-852b-421be2dc7daf"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/tvm/script/highlight.py:117: UserWarning: No module named 'black'\n",
            "To print formatted TVM script, please install the formatter 'Black':\n",
            "/usr/bin/python3 -m pip install \"black==22.3.0\" --upgrade --user\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<div class=\"highlight\" style=\"background: \"><pre style=\"line-height: 125%;\"><span></span><span style=\"color: #007979; font-style: italic\"># from tvm.script import tir as T</span>\n",
              "\n",
              "<span style=\"color: #AA22FF\">@T</span><span style=\"color: #AA22FF; font-weight: bold\">.</span>prim_func\n",
              "<span style=\"color: #008000; font-weight: bold\">def</span> <span style=\"color: #0000FF\">main</span>(A: T<span style=\"color: #AA22FF; font-weight: bold\">.</span>Buffer((<span style=\"color: #008000\">128</span>, <span style=\"color: #008000\">128</span>), <span style=\"color: #BA2121\">&quot;float32&quot;</span>), B: T<span style=\"color: #AA22FF; font-weight: bold\">.</span>Buffer((<span style=\"color: #008000\">128</span>, <span style=\"color: #008000\">128</span>), <span style=\"color: #BA2121\">&quot;float32&quot;</span>), relu: T<span style=\"color: #AA22FF; font-weight: bold\">.</span>Buffer((<span style=\"color: #008000\">128</span>, <span style=\"color: #008000\">128</span>), <span style=\"color: #BA2121\">&quot;float32&quot;</span>)):\n",
              "    T<span style=\"color: #AA22FF; font-weight: bold\">.</span>func_attr({<span style=\"color: #BA2121\">&quot;global_symbol&quot;</span>: <span style=\"color: #BA2121\">&quot;main&quot;</span>, <span style=\"color: #BA2121\">&quot;tir.noalias&quot;</span>: T<span style=\"color: #AA22FF; font-weight: bold\">.</span>bool(<span style=\"color: #008000; font-weight: bold\">True</span>)})\n",
              "    <span style=\"color: #007979; font-style: italic\"># with T.block(&quot;root&quot;):</span>\n",
              "    matmul <span style=\"color: #AA22FF; font-weight: bold\">=</span> T<span style=\"color: #AA22FF; font-weight: bold\">.</span>alloc_buffer((<span style=\"color: #008000\">128</span>, <span style=\"color: #008000\">128</span>))\n",
              "    <span style=\"color: #008000; font-weight: bold\">for</span> i, j, k <span style=\"color: #008000; font-weight: bold\">in</span> T<span style=\"color: #AA22FF; font-weight: bold\">.</span>grid(<span style=\"color: #008000\">128</span>, <span style=\"color: #008000\">128</span>, <span style=\"color: #008000\">128</span>):\n",
              "        <span style=\"color: #008000; font-weight: bold\">with</span> T<span style=\"color: #AA22FF; font-weight: bold\">.</span>block(<span style=\"color: #BA2121\">&quot;matmul&quot;</span>):\n",
              "            v_i, v_j, v_k <span style=\"color: #AA22FF; font-weight: bold\">=</span> T<span style=\"color: #AA22FF; font-weight: bold\">.</span>axis<span style=\"color: #AA22FF; font-weight: bold\">.</span>remap(<span style=\"color: #BA2121\">&quot;SSR&quot;</span>, [i, j, k])\n",
              "            T<span style=\"color: #AA22FF; font-weight: bold\">.</span>reads(A[v_i, v_k], B[v_k, v_j])\n",
              "            T<span style=\"color: #AA22FF; font-weight: bold\">.</span>writes(matmul[v_i, v_j])\n",
              "            <span style=\"color: #008000; font-weight: bold\">with</span> T<span style=\"color: #AA22FF; font-weight: bold\">.</span>init():\n",
              "                matmul[v_i, v_j] <span style=\"color: #AA22FF; font-weight: bold\">=</span> T<span style=\"color: #AA22FF; font-weight: bold\">.</span>float32(<span style=\"color: #008000\">0</span>)\n",
              "            matmul[v_i, v_j] <span style=\"color: #AA22FF; font-weight: bold\">=</span> matmul[v_i, v_j] <span style=\"color: #AA22FF; font-weight: bold\">+</span> A[v_i, v_k] <span style=\"color: #AA22FF; font-weight: bold\">*</span> B[v_k, v_j]\n",
              "    <span style=\"color: #008000; font-weight: bold\">for</span> i0, i1 <span style=\"color: #008000; font-weight: bold\">in</span> T<span style=\"color: #AA22FF; font-weight: bold\">.</span>grid(<span style=\"color: #008000\">128</span>, <span style=\"color: #008000\">128</span>):\n",
              "        <span style=\"color: #008000; font-weight: bold\">with</span> T<span style=\"color: #AA22FF; font-weight: bold\">.</span>block(<span style=\"color: #BA2121\">&quot;relu&quot;</span>):\n",
              "            v_i0, v_i1 <span style=\"color: #AA22FF; font-weight: bold\">=</span> T<span style=\"color: #AA22FF; font-weight: bold\">.</span>axis<span style=\"color: #AA22FF; font-weight: bold\">.</span>remap(<span style=\"color: #BA2121\">&quot;SS&quot;</span>, [i0, i1])\n",
              "            T<span style=\"color: #AA22FF; font-weight: bold\">.</span>reads(matmul[v_i0, v_i1])\n",
              "            T<span style=\"color: #AA22FF; font-weight: bold\">.</span>writes(relu[v_i0, v_i1])\n",
              "            relu[v_i0, v_i1] <span style=\"color: #AA22FF; font-weight: bold\">=</span> T<span style=\"color: #AA22FF; font-weight: bold\">.</span>max(matmul[v_i0, v_i1], T<span style=\"color: #AA22FF; font-weight: bold\">.</span>float32(<span style=\"color: #008000\">0</span>))\n",
              "</pre></div>\n"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "note only A B D are passed in, and C omitted.\n",
        "\n",
        "above, we can see prim func create temp buffer for C/matmul.\n",
        "\n",
        "we can still pass in C. however, the fusion is less advanced."
      ],
      "metadata": {
        "id": "uhIgpeRijYMY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "te.create_prim_func([A, B, C, D]).show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 456
        },
        "id": "JYPdMieFjWEN",
        "outputId": "e88a8678-f3de-4d3f-d95a-5b8073321bb6"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/tvm/script/highlight.py:117: UserWarning: No module named 'black'\n",
            "To print formatted TVM script, please install the formatter 'Black':\n",
            "/usr/bin/python3 -m pip install \"black==22.3.0\" --upgrade --user\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<div class=\"highlight\" style=\"background: \"><pre style=\"line-height: 125%;\"><span></span><span style=\"color: #007979; font-style: italic\"># from tvm.script import tir as T</span>\n",
              "\n",
              "<span style=\"color: #AA22FF\">@T</span><span style=\"color: #AA22FF; font-weight: bold\">.</span>prim_func\n",
              "<span style=\"color: #008000; font-weight: bold\">def</span> <span style=\"color: #0000FF\">main</span>(A: T<span style=\"color: #AA22FF; font-weight: bold\">.</span>Buffer((<span style=\"color: #008000\">128</span>, <span style=\"color: #008000\">128</span>), <span style=\"color: #BA2121\">&quot;float32&quot;</span>), B: T<span style=\"color: #AA22FF; font-weight: bold\">.</span>Buffer((<span style=\"color: #008000\">128</span>, <span style=\"color: #008000\">128</span>), <span style=\"color: #BA2121\">&quot;float32&quot;</span>), matmul: T<span style=\"color: #AA22FF; font-weight: bold\">.</span>Buffer((<span style=\"color: #008000\">128</span>, <span style=\"color: #008000\">128</span>), <span style=\"color: #BA2121\">&quot;float32&quot;</span>), relu: T<span style=\"color: #AA22FF; font-weight: bold\">.</span>Buffer((<span style=\"color: #008000\">128</span>, <span style=\"color: #008000\">128</span>), <span style=\"color: #BA2121\">&quot;float32&quot;</span>)):\n",
              "    T<span style=\"color: #AA22FF; font-weight: bold\">.</span>func_attr({<span style=\"color: #BA2121\">&quot;global_symbol&quot;</span>: <span style=\"color: #BA2121\">&quot;main&quot;</span>, <span style=\"color: #BA2121\">&quot;tir.noalias&quot;</span>: T<span style=\"color: #AA22FF; font-weight: bold\">.</span>bool(<span style=\"color: #008000; font-weight: bold\">True</span>)})\n",
              "    <span style=\"color: #007979; font-style: italic\"># with T.block(&quot;root&quot;):</span>\n",
              "    <span style=\"color: #008000; font-weight: bold\">for</span> i, j, k <span style=\"color: #008000; font-weight: bold\">in</span> T<span style=\"color: #AA22FF; font-weight: bold\">.</span>grid(<span style=\"color: #008000\">128</span>, <span style=\"color: #008000\">128</span>, <span style=\"color: #008000\">128</span>):\n",
              "        <span style=\"color: #008000; font-weight: bold\">with</span> T<span style=\"color: #AA22FF; font-weight: bold\">.</span>block(<span style=\"color: #BA2121\">&quot;matmul&quot;</span>):\n",
              "            v_i, v_j, v_k <span style=\"color: #AA22FF; font-weight: bold\">=</span> T<span style=\"color: #AA22FF; font-weight: bold\">.</span>axis<span style=\"color: #AA22FF; font-weight: bold\">.</span>remap(<span style=\"color: #BA2121\">&quot;SSR&quot;</span>, [i, j, k])\n",
              "            T<span style=\"color: #AA22FF; font-weight: bold\">.</span>reads(A[v_i, v_k], B[v_k, v_j])\n",
              "            T<span style=\"color: #AA22FF; font-weight: bold\">.</span>writes(matmul[v_i, v_j])\n",
              "            <span style=\"color: #008000; font-weight: bold\">with</span> T<span style=\"color: #AA22FF; font-weight: bold\">.</span>init():\n",
              "                matmul[v_i, v_j] <span style=\"color: #AA22FF; font-weight: bold\">=</span> T<span style=\"color: #AA22FF; font-weight: bold\">.</span>float32(<span style=\"color: #008000\">0</span>)\n",
              "            matmul[v_i, v_j] <span style=\"color: #AA22FF; font-weight: bold\">=</span> matmul[v_i, v_j] <span style=\"color: #AA22FF; font-weight: bold\">+</span> A[v_i, v_k] <span style=\"color: #AA22FF; font-weight: bold\">*</span> B[v_k, v_j]\n",
              "    <span style=\"color: #008000; font-weight: bold\">for</span> i0, i1 <span style=\"color: #008000; font-weight: bold\">in</span> T<span style=\"color: #AA22FF; font-weight: bold\">.</span>grid(<span style=\"color: #008000\">128</span>, <span style=\"color: #008000\">128</span>):\n",
              "        <span style=\"color: #008000; font-weight: bold\">with</span> T<span style=\"color: #AA22FF; font-weight: bold\">.</span>block(<span style=\"color: #BA2121\">&quot;relu&quot;</span>):\n",
              "            v_i0, v_i1 <span style=\"color: #AA22FF; font-weight: bold\">=</span> T<span style=\"color: #AA22FF; font-weight: bold\">.</span>axis<span style=\"color: #AA22FF; font-weight: bold\">.</span>remap(<span style=\"color: #BA2121\">&quot;SS&quot;</span>, [i0, i1])\n",
              "            T<span style=\"color: #AA22FF; font-weight: bold\">.</span>reads(matmul[v_i0, v_i1])\n",
              "            T<span style=\"color: #AA22FF; font-weight: bold\">.</span>writes(relu[v_i0, v_i1])\n",
              "            relu[v_i0, v_i1] <span style=\"color: #AA22FF; font-weight: bold\">=</span> T<span style=\"color: #AA22FF; font-weight: bold\">.</span>max(matmul[v_i0, v_i1], T<span style=\"color: #AA22FF; font-weight: bold\">.</span>float32(<span style=\"color: #008000\">0</span>))\n",
              "</pre></div>\n"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "note how C/matmul is passed in."
      ],
      "metadata": {
        "id": "P9SY6oHzkCIQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Connect IRModules via BlockBuilder \n",
        "\n",
        "build end to end model with IRModule defined above"
      ],
      "metadata": {
        "id": "ljzoFsZ2kO4G"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# define input\n",
        "A = relax.Var(\"A\", relax.TensorStructInfo((128, 128), f32))\n",
        "B = relax.Var(\"B\", relax.TensorStructInfo((128, 128), f32))\n",
        "\n",
        "# create block builder\n",
        "bb = relax.BlockBuilder()\n",
        "\n",
        "with bb.function(\"main\"):\n",
        "    with bb.dataflow():\n",
        "        C = bb.emit_te(te_matmul, A, B)\n",
        "        D = bb.emit_te(te_relu, C)\n",
        "        R = bb.emit_output(D)\n",
        "    bb.emit_func_output(R, params=[A, B])\n",
        "\n",
        "# show IRModule\n",
        "MyModule = bb.get()\n",
        "print(type(MyModule))\n",
        "MyModule.show()"
      ],
      "metadata": {
        "id": "xvNmP7elax5p",
        "outputId": "b6056bf7-43fb-47f2-c9e0-dd440200fd0b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 806
        }
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'tvm.ir.module.IRModule'>\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/tvm/script/highlight.py:117: UserWarning: No module named 'black'\n",
            "To print formatted TVM script, please install the formatter 'Black':\n",
            "/usr/bin/python3 -m pip install \"black==22.3.0\" --upgrade --user\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<div class=\"highlight\" style=\"background: \"><pre style=\"line-height: 125%;\"><span></span><span style=\"color: #007979; font-style: italic\"># from tvm.script import ir as I</span>\n",
              "<span style=\"color: #007979; font-style: italic\"># from tvm.script import tir as T</span>\n",
              "<span style=\"color: #007979; font-style: italic\"># from tvm.script import relax as R</span>\n",
              "\n",
              "<span style=\"color: #AA22FF\">@I</span><span style=\"color: #AA22FF; font-weight: bold\">.</span>ir_module\n",
              "<span style=\"color: #008000; font-weight: bold\">class</span> <span style=\"color: #0000FF; font-weight: bold\">Module</span>:\n",
              "    <span style=\"color: #AA22FF\">@T</span><span style=\"color: #AA22FF; font-weight: bold\">.</span>prim_func\n",
              "    <span style=\"color: #008000; font-weight: bold\">def</span> <span style=\"color: #0000FF\">te_matmul</span>(A: T<span style=\"color: #AA22FF; font-weight: bold\">.</span>Buffer((T<span style=\"color: #AA22FF; font-weight: bold\">.</span>int64(<span style=\"color: #008000\">128</span>), T<span style=\"color: #AA22FF; font-weight: bold\">.</span>int64(<span style=\"color: #008000\">128</span>)), <span style=\"color: #BA2121\">&quot;float32&quot;</span>), B: T<span style=\"color: #AA22FF; font-weight: bold\">.</span>Buffer((T<span style=\"color: #AA22FF; font-weight: bold\">.</span>int64(<span style=\"color: #008000\">128</span>), T<span style=\"color: #AA22FF; font-weight: bold\">.</span>int64(<span style=\"color: #008000\">128</span>)), <span style=\"color: #BA2121\">&quot;float32&quot;</span>), matmul: T<span style=\"color: #AA22FF; font-weight: bold\">.</span>Buffer((T<span style=\"color: #AA22FF; font-weight: bold\">.</span>int64(<span style=\"color: #008000\">128</span>), T<span style=\"color: #AA22FF; font-weight: bold\">.</span>int64(<span style=\"color: #008000\">128</span>)), <span style=\"color: #BA2121\">&quot;float32&quot;</span>)):\n",
              "        T<span style=\"color: #AA22FF; font-weight: bold\">.</span>func_attr({<span style=\"color: #BA2121\">&quot;tir.noalias&quot;</span>: T<span style=\"color: #AA22FF; font-weight: bold\">.</span>bool(<span style=\"color: #008000; font-weight: bold\">True</span>)})\n",
              "        <span style=\"color: #007979; font-style: italic\"># with T.block(&quot;root&quot;):</span>\n",
              "        <span style=\"color: #008000; font-weight: bold\">for</span> i, j, k <span style=\"color: #008000; font-weight: bold\">in</span> T<span style=\"color: #AA22FF; font-weight: bold\">.</span>grid(T<span style=\"color: #AA22FF; font-weight: bold\">.</span>int64(<span style=\"color: #008000\">128</span>), T<span style=\"color: #AA22FF; font-weight: bold\">.</span>int64(<span style=\"color: #008000\">128</span>), T<span style=\"color: #AA22FF; font-weight: bold\">.</span>int64(<span style=\"color: #008000\">128</span>)):\n",
              "            <span style=\"color: #008000; font-weight: bold\">with</span> T<span style=\"color: #AA22FF; font-weight: bold\">.</span>block(<span style=\"color: #BA2121\">&quot;matmul&quot;</span>):\n",
              "                v_i, v_j, v_k <span style=\"color: #AA22FF; font-weight: bold\">=</span> T<span style=\"color: #AA22FF; font-weight: bold\">.</span>axis<span style=\"color: #AA22FF; font-weight: bold\">.</span>remap(<span style=\"color: #BA2121\">&quot;SSR&quot;</span>, [i, j, k])\n",
              "                T<span style=\"color: #AA22FF; font-weight: bold\">.</span>reads(A[v_i, v_k], B[v_k, v_j])\n",
              "                T<span style=\"color: #AA22FF; font-weight: bold\">.</span>writes(matmul[v_i, v_j])\n",
              "                <span style=\"color: #008000; font-weight: bold\">with</span> T<span style=\"color: #AA22FF; font-weight: bold\">.</span>init():\n",
              "                    matmul[v_i, v_j] <span style=\"color: #AA22FF; font-weight: bold\">=</span> T<span style=\"color: #AA22FF; font-weight: bold\">.</span>float32(<span style=\"color: #008000\">0</span>)\n",
              "                matmul[v_i, v_j] <span style=\"color: #AA22FF; font-weight: bold\">=</span> matmul[v_i, v_j] <span style=\"color: #AA22FF; font-weight: bold\">+</span> A[v_i, v_k] <span style=\"color: #AA22FF; font-weight: bold\">*</span> B[v_k, v_j]\n",
              "\n",
              "    <span style=\"color: #AA22FF\">@T</span><span style=\"color: #AA22FF; font-weight: bold\">.</span>prim_func\n",
              "    <span style=\"color: #008000; font-weight: bold\">def</span> <span style=\"color: #0000FF\">te_relu</span>(A: T<span style=\"color: #AA22FF; font-weight: bold\">.</span>Buffer((T<span style=\"color: #AA22FF; font-weight: bold\">.</span>int64(<span style=\"color: #008000\">128</span>), T<span style=\"color: #AA22FF; font-weight: bold\">.</span>int64(<span style=\"color: #008000\">128</span>)), <span style=\"color: #BA2121\">&quot;float32&quot;</span>), relu: T<span style=\"color: #AA22FF; font-weight: bold\">.</span>Buffer((T<span style=\"color: #AA22FF; font-weight: bold\">.</span>int64(<span style=\"color: #008000\">128</span>), T<span style=\"color: #AA22FF; font-weight: bold\">.</span>int64(<span style=\"color: #008000\">128</span>)), <span style=\"color: #BA2121\">&quot;float32&quot;</span>)):\n",
              "        T<span style=\"color: #AA22FF; font-weight: bold\">.</span>func_attr({<span style=\"color: #BA2121\">&quot;tir.noalias&quot;</span>: T<span style=\"color: #AA22FF; font-weight: bold\">.</span>bool(<span style=\"color: #008000; font-weight: bold\">True</span>)})\n",
              "        <span style=\"color: #007979; font-style: italic\"># with T.block(&quot;root&quot;):</span>\n",
              "        <span style=\"color: #008000; font-weight: bold\">for</span> i0, i1 <span style=\"color: #008000; font-weight: bold\">in</span> T<span style=\"color: #AA22FF; font-weight: bold\">.</span>grid(T<span style=\"color: #AA22FF; font-weight: bold\">.</span>int64(<span style=\"color: #008000\">128</span>), T<span style=\"color: #AA22FF; font-weight: bold\">.</span>int64(<span style=\"color: #008000\">128</span>)):\n",
              "            <span style=\"color: #008000; font-weight: bold\">with</span> T<span style=\"color: #AA22FF; font-weight: bold\">.</span>block(<span style=\"color: #BA2121\">&quot;relu&quot;</span>):\n",
              "                v_i0, v_i1 <span style=\"color: #AA22FF; font-weight: bold\">=</span> T<span style=\"color: #AA22FF; font-weight: bold\">.</span>axis<span style=\"color: #AA22FF; font-weight: bold\">.</span>remap(<span style=\"color: #BA2121\">&quot;SS&quot;</span>, [i0, i1])\n",
              "                T<span style=\"color: #AA22FF; font-weight: bold\">.</span>reads(A[v_i0, v_i1])\n",
              "                T<span style=\"color: #AA22FF; font-weight: bold\">.</span>writes(relu[v_i0, v_i1])\n",
              "                relu[v_i0, v_i1] <span style=\"color: #AA22FF; font-weight: bold\">=</span> T<span style=\"color: #AA22FF; font-weight: bold\">.</span>max(A[v_i0, v_i1], T<span style=\"color: #AA22FF; font-weight: bold\">.</span>float32(<span style=\"color: #008000\">0</span>))\n",
              "\n",
              "    <span style=\"color: #AA22FF\">@R</span><span style=\"color: #AA22FF; font-weight: bold\">.</span>function\n",
              "    <span style=\"color: #008000; font-weight: bold\">def</span> <span style=\"color: #0000FF\">main</span>(A: R<span style=\"color: #AA22FF; font-weight: bold\">.</span>Tensor((<span style=\"color: #008000\">128</span>, <span style=\"color: #008000\">128</span>), dtype<span style=\"color: #AA22FF; font-weight: bold\">=</span><span style=\"color: #BA2121\">&quot;float32&quot;</span>), B: R<span style=\"color: #AA22FF; font-weight: bold\">.</span>Tensor((<span style=\"color: #008000\">128</span>, <span style=\"color: #008000\">128</span>), dtype<span style=\"color: #AA22FF; font-weight: bold\">=</span><span style=\"color: #BA2121\">&quot;float32&quot;</span>)) <span style=\"color: #AA22FF; font-weight: bold\">-&gt;</span> R<span style=\"color: #AA22FF; font-weight: bold\">.</span>Tensor((<span style=\"color: #008000\">128</span>, <span style=\"color: #008000\">128</span>), dtype<span style=\"color: #AA22FF; font-weight: bold\">=</span><span style=\"color: #BA2121\">&quot;float32&quot;</span>):\n",
              "        cls <span style=\"color: #AA22FF; font-weight: bold\">=</span> Module\n",
              "        <span style=\"color: #008000; font-weight: bold\">with</span> R<span style=\"color: #AA22FF; font-weight: bold\">.</span>dataflow():\n",
              "            lv <span style=\"color: #AA22FF; font-weight: bold\">=</span> R<span style=\"color: #AA22FF; font-weight: bold\">.</span>call_tir(cls<span style=\"color: #AA22FF; font-weight: bold\">.</span>te_matmul, (A, B), out_sinfo<span style=\"color: #AA22FF; font-weight: bold\">=</span>R<span style=\"color: #AA22FF; font-weight: bold\">.</span>Tensor((<span style=\"color: #008000\">128</span>, <span style=\"color: #008000\">128</span>), dtype<span style=\"color: #AA22FF; font-weight: bold\">=</span><span style=\"color: #BA2121\">&quot;float32&quot;</span>))\n",
              "            lv1 <span style=\"color: #AA22FF; font-weight: bold\">=</span> R<span style=\"color: #AA22FF; font-weight: bold\">.</span>call_tir(cls<span style=\"color: #AA22FF; font-weight: bold\">.</span>te_relu, (lv,), out_sinfo<span style=\"color: #AA22FF; font-weight: bold\">=</span>R<span style=\"color: #AA22FF; font-weight: bold\">.</span>Tensor((<span style=\"color: #008000\">128</span>, <span style=\"color: #008000\">128</span>), dtype<span style=\"color: #AA22FF; font-weight: bold\">=</span><span style=\"color: #BA2121\">&quot;float32&quot;</span>))\n",
              "            gv: R<span style=\"color: #AA22FF; font-weight: bold\">.</span>Tensor((<span style=\"color: #008000\">128</span>, <span style=\"color: #008000\">128</span>), dtype<span style=\"color: #AA22FF; font-weight: bold\">=</span><span style=\"color: #BA2121\">&quot;float32&quot;</span>) <span style=\"color: #AA22FF; font-weight: bold\">=</span> lv1\n",
              "            R<span style=\"color: #AA22FF; font-weight: bold\">.</span>output(gv)\n",
              "        <span style=\"color: #008000; font-weight: bold\">return</span> gv\n",
              "</pre></div>\n"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "compare this model to the end-to-end model in last notebook:\n",
        "\n",
        "- pretty much the same\n",
        "- much less code wrote to achieve"
      ],
      "metadata": {
        "id": "jsCaZZQHcPXC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Import model from PyTorch\n",
        "\n",
        "now we know how to construct an IRModule programmatically.\n",
        "\n",
        "lets convert a PyTorch model into IRModule format."
      ],
      "metadata": {
        "id": "Tt_YeYelctS1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# define the PyTorch model (and convert it to IRModule)\n",
        "class MyModel(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(MyModel, self).__init__()\n",
        "        self.weight = nn.Parameter(torch.randn(128, 128))\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = torch.matmul(x, self.weight)\n",
        "        x = torch.relu(x)\n",
        "        return x"
      ],
      "metadata": {
        "id": "qoe5z6pehZaC"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### TorchFX\n",
        "\n",
        "to trace a graph of PyTorch model.  \n",
        "(util tool to visualize model)"
      ],
      "metadata": {
        "id": "viFiFmfKiieK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = MyModel()\n",
        "fx_module = fx.symbolic_trace(model)\n",
        "fx_module.graph.print_tabular()"
      ],
      "metadata": {
        "id": "Z-zQXKscicTZ",
        "outputId": "d66f6c76-8f28-45e3-b77f-383b767fb395",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "opcode         name    target                                                     args         kwargs\n",
            "-------------  ------  ---------------------------------------------------------  -----------  --------\n",
            "placeholder    x       x                                                          ()           {}\n",
            "get_attr       weight  weight                                                     ()           {}\n",
            "call_function  matmul  <built-in method matmul of type object at 0x7f17ec112880>  (x, weight)  {}\n",
            "call_function  relu    <built-in method relu of type object at 0x7f17ec112880>    (matmul,)    {}\n",
            "output         output  output                                                     (relu,)      {}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for node in fx_module.graph.nodes:\n",
        "    print(node.op)"
      ],
      "metadata": {
        "id": "PuGtlkAqm6th",
        "outputId": "5824ae23-fdef-43e7-c306-212c9100cae9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "placeholder\n",
            "get_attr\n",
            "call_function\n",
            "call_function\n",
            "output\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Create Map Func\n",
        "\n",
        "workflow:\n",
        "1. create `node_map` to map `fx.Node` to `relax.Var`\n",
        "2. iterate over nodes in `fx.graph` in topological order\n",
        "3. compute mapped output"
      ],
      "metadata": {
        "id": "Q2KFUw8MjHGj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def map_param(param: nn.Parameter):\n",
        "    \"\"\"helper func\"\"\"\n",
        "    ndim = len(param.data.shape)\n",
        "    return relax.const(\n",
        "        param.data.cpu().numpy(), relax.DynTensorType(ndim, \"float32\")\n",
        "    )\n",
        "\n",
        "def fetch_attr(fx_mod, target: str):\n",
        "    \"\"\"helper func\"\"\"\n",
        "    target_atoms = target.split('.')\n",
        "    attr_itr = fx_mod\n",
        "    for i, atom, in enumerate(target_atoms):\n",
        "        if not hasattr(attr_itr, atom):\n",
        "            raise RuntimeError(f\"Node referenced nonexistant target {'.'.join(target_atoms[:i])}\")\n",
        "        attr_itr = getattr(attr_itr, atom)\n",
        "    return attr_itr\n",
        "\n",
        "def from_fx(fx_mod, input_shapes, call_function_map, call_module_map):\n",
        "    input_index = 0\n",
        "    node_map = {}\n",
        "    named_modules = dict(fx_mod.named_modules())\n",
        "\n",
        "    bb = relax.BlockBuilder()\n",
        "\n",
        "    fn_inputs = []\n",
        "    fn_output = None\n",
        "    with bb.function(\"main\"):\n",
        "        with bb.dataflow():\n",
        "            for node in fx_mod.graph.nodes:\n",
        "                if node.op == 'placeholder': # found input vars\n",
        "                    shape = input_shapes[input_index]\n",
        "                    input_index += 1\n",
        "                    input_var = relax.Var(\n",
        "                        node.target, relax.TensorStructInfo(shape, f32)\n",
        "                    )\n",
        "                    fn_inputs.append(input_var)\n",
        "                    node_map[node] = input_var\n",
        "                elif node.op == 'get_attr': # found parameters\n",
        "                    attr = fetch_attr(fx_mod, node.target)\n",
        "                    param = map_param(attr)\n",
        "                    node_map[node] = param\n",
        "                elif node.op == 'call_function': # found a func\n",
        "                    func = call_function_map[node.target](bb, node_map, node)\n",
        "                    node_map[node] = func\n",
        "                elif node.op == 'call_module':\n",
        "                    named_module = named_modules[node.target]\n",
        "                    node_map[node] = call_module_map[type(named_module)](bb, node_map, node, named_module)\n",
        "                elif node.op == 'output':\n",
        "                    output = node_map[node.args[0]]\n",
        "                    assert fn_output is None\n",
        "                    fn_output = bb.emit_output(output)\n",
        "        bb.emit_func_output(output, fn_inputs)\n",
        "    return bb.get()\n",
        "\n"
      ],
      "metadata": {
        "id": "9r4Pg1oujDDo"
      },
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# supply translation rule via map\n",
        "def map_matmul(bb, node_map, node: fx.Node):\n",
        "    A = node_map[node.args[0]]\n",
        "    B = node_map[node.args[1]]\n",
        "    return bb.emit_te(te_matmul, A, B)\n",
        "\n",
        "def map_relu(bb, node_map, node: fx.Node):\n",
        "    A = node_map[node.args[0]]\n",
        "    return bb.emit_te(te_relu, A)"
      ],
      "metadata": {
        "id": "M4yxPai0oIy0"
      },
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# create IRModule\n",
        "MyModule = from_fx(\n",
        "    fx_module,\n",
        "    input_shapes = [(1, 128)],\n",
        "    call_function_map = {\n",
        "      torch.matmul: map_matmul,\n",
        "      torch.relu: map_relu,\n",
        "    },\n",
        "    call_module_map={},\n",
        ")\n",
        "\n",
        "MyModule.show()"
      ],
      "metadata": {
        "id": "lwn-eBnWovwW",
        "outputId": "8e423891-f5ea-4d1c-83b8-a88217c69c0a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 824
        }
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/tvm/script/highlight.py:117: UserWarning: No module named 'black'\n",
            "To print formatted TVM script, please install the formatter 'Black':\n",
            "/usr/bin/python3 -m pip install \"black==22.3.0\" --upgrade --user\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<div class=\"highlight\" style=\"background: \"><pre style=\"line-height: 125%;\"><span></span><span style=\"color: #007979; font-style: italic\"># from tvm.script import ir as I</span>\n",
              "<span style=\"color: #007979; font-style: italic\"># from tvm.script import tir as T</span>\n",
              "<span style=\"color: #007979; font-style: italic\"># from tvm.script import relax as R</span>\n",
              "\n",
              "<span style=\"color: #AA22FF\">@I</span><span style=\"color: #AA22FF; font-weight: bold\">.</span>ir_module\n",
              "<span style=\"color: #008000; font-weight: bold\">class</span> <span style=\"color: #0000FF; font-weight: bold\">Module</span>:\n",
              "    <span style=\"color: #AA22FF\">@T</span><span style=\"color: #AA22FF; font-weight: bold\">.</span>prim_func\n",
              "    <span style=\"color: #008000; font-weight: bold\">def</span> <span style=\"color: #0000FF\">te_matmul</span>(A: T<span style=\"color: #AA22FF; font-weight: bold\">.</span>Buffer((T<span style=\"color: #AA22FF; font-weight: bold\">.</span>int64(<span style=\"color: #008000\">1</span>), T<span style=\"color: #AA22FF; font-weight: bold\">.</span>int64(<span style=\"color: #008000\">128</span>)), <span style=\"color: #BA2121\">&quot;float32&quot;</span>), B: T<span style=\"color: #AA22FF; font-weight: bold\">.</span>Buffer((T<span style=\"color: #AA22FF; font-weight: bold\">.</span>int64(<span style=\"color: #008000\">128</span>), T<span style=\"color: #AA22FF; font-weight: bold\">.</span>int64(<span style=\"color: #008000\">128</span>)), <span style=\"color: #BA2121\">&quot;float32&quot;</span>), matmul: T<span style=\"color: #AA22FF; font-weight: bold\">.</span>Buffer((T<span style=\"color: #AA22FF; font-weight: bold\">.</span>int64(<span style=\"color: #008000\">1</span>), T<span style=\"color: #AA22FF; font-weight: bold\">.</span>int64(<span style=\"color: #008000\">128</span>)), <span style=\"color: #BA2121\">&quot;float32&quot;</span>)):\n",
              "        T<span style=\"color: #AA22FF; font-weight: bold\">.</span>func_attr({<span style=\"color: #BA2121\">&quot;tir.noalias&quot;</span>: T<span style=\"color: #AA22FF; font-weight: bold\">.</span>bool(<span style=\"color: #008000; font-weight: bold\">True</span>)})\n",
              "        <span style=\"color: #007979; font-style: italic\"># with T.block(&quot;root&quot;):</span>\n",
              "        <span style=\"color: #008000; font-weight: bold\">for</span> i, j, k <span style=\"color: #008000; font-weight: bold\">in</span> T<span style=\"color: #AA22FF; font-weight: bold\">.</span>grid(T<span style=\"color: #AA22FF; font-weight: bold\">.</span>int64(<span style=\"color: #008000\">1</span>), T<span style=\"color: #AA22FF; font-weight: bold\">.</span>int64(<span style=\"color: #008000\">128</span>), T<span style=\"color: #AA22FF; font-weight: bold\">.</span>int64(<span style=\"color: #008000\">128</span>)):\n",
              "            <span style=\"color: #008000; font-weight: bold\">with</span> T<span style=\"color: #AA22FF; font-weight: bold\">.</span>block(<span style=\"color: #BA2121\">&quot;matmul&quot;</span>):\n",
              "                v_i, v_j, v_k <span style=\"color: #AA22FF; font-weight: bold\">=</span> T<span style=\"color: #AA22FF; font-weight: bold\">.</span>axis<span style=\"color: #AA22FF; font-weight: bold\">.</span>remap(<span style=\"color: #BA2121\">&quot;SSR&quot;</span>, [i, j, k])\n",
              "                T<span style=\"color: #AA22FF; font-weight: bold\">.</span>reads(A[v_i, v_k], B[v_k, v_j])\n",
              "                T<span style=\"color: #AA22FF; font-weight: bold\">.</span>writes(matmul[v_i, v_j])\n",
              "                <span style=\"color: #008000; font-weight: bold\">with</span> T<span style=\"color: #AA22FF; font-weight: bold\">.</span>init():\n",
              "                    matmul[v_i, v_j] <span style=\"color: #AA22FF; font-weight: bold\">=</span> T<span style=\"color: #AA22FF; font-weight: bold\">.</span>float32(<span style=\"color: #008000\">0</span>)\n",
              "                matmul[v_i, v_j] <span style=\"color: #AA22FF; font-weight: bold\">=</span> matmul[v_i, v_j] <span style=\"color: #AA22FF; font-weight: bold\">+</span> A[v_i, v_k] <span style=\"color: #AA22FF; font-weight: bold\">*</span> B[v_k, v_j]\n",
              "\n",
              "    <span style=\"color: #AA22FF\">@T</span><span style=\"color: #AA22FF; font-weight: bold\">.</span>prim_func\n",
              "    <span style=\"color: #008000; font-weight: bold\">def</span> <span style=\"color: #0000FF\">te_relu</span>(A: T<span style=\"color: #AA22FF; font-weight: bold\">.</span>Buffer((T<span style=\"color: #AA22FF; font-weight: bold\">.</span>int64(<span style=\"color: #008000\">1</span>), T<span style=\"color: #AA22FF; font-weight: bold\">.</span>int64(<span style=\"color: #008000\">128</span>)), <span style=\"color: #BA2121\">&quot;float32&quot;</span>), relu: T<span style=\"color: #AA22FF; font-weight: bold\">.</span>Buffer((T<span style=\"color: #AA22FF; font-weight: bold\">.</span>int64(<span style=\"color: #008000\">1</span>), T<span style=\"color: #AA22FF; font-weight: bold\">.</span>int64(<span style=\"color: #008000\">128</span>)), <span style=\"color: #BA2121\">&quot;float32&quot;</span>)):\n",
              "        T<span style=\"color: #AA22FF; font-weight: bold\">.</span>func_attr({<span style=\"color: #BA2121\">&quot;tir.noalias&quot;</span>: T<span style=\"color: #AA22FF; font-weight: bold\">.</span>bool(<span style=\"color: #008000; font-weight: bold\">True</span>)})\n",
              "        <span style=\"color: #007979; font-style: italic\"># with T.block(&quot;root&quot;):</span>\n",
              "        <span style=\"color: #008000; font-weight: bold\">for</span> i0, i1 <span style=\"color: #008000; font-weight: bold\">in</span> T<span style=\"color: #AA22FF; font-weight: bold\">.</span>grid(T<span style=\"color: #AA22FF; font-weight: bold\">.</span>int64(<span style=\"color: #008000\">1</span>), T<span style=\"color: #AA22FF; font-weight: bold\">.</span>int64(<span style=\"color: #008000\">128</span>)):\n",
              "            <span style=\"color: #008000; font-weight: bold\">with</span> T<span style=\"color: #AA22FF; font-weight: bold\">.</span>block(<span style=\"color: #BA2121\">&quot;relu&quot;</span>):\n",
              "                v_i0, v_i1 <span style=\"color: #AA22FF; font-weight: bold\">=</span> T<span style=\"color: #AA22FF; font-weight: bold\">.</span>axis<span style=\"color: #AA22FF; font-weight: bold\">.</span>remap(<span style=\"color: #BA2121\">&quot;SS&quot;</span>, [i0, i1])\n",
              "                T<span style=\"color: #AA22FF; font-weight: bold\">.</span>reads(A[v_i0, v_i1])\n",
              "                T<span style=\"color: #AA22FF; font-weight: bold\">.</span>writes(relu[v_i0, v_i1])\n",
              "                relu[v_i0, v_i1] <span style=\"color: #AA22FF; font-weight: bold\">=</span> T<span style=\"color: #AA22FF; font-weight: bold\">.</span>max(A[v_i0, v_i1], T<span style=\"color: #AA22FF; font-weight: bold\">.</span>float32(<span style=\"color: #008000\">0</span>))\n",
              "\n",
              "    <span style=\"color: #AA22FF\">@R</span><span style=\"color: #AA22FF; font-weight: bold\">.</span>function\n",
              "    <span style=\"color: #008000; font-weight: bold\">def</span> <span style=\"color: #0000FF\">main</span>(x: R<span style=\"color: #AA22FF; font-weight: bold\">.</span>Tensor((<span style=\"color: #008000\">1</span>, <span style=\"color: #008000\">128</span>), dtype<span style=\"color: #AA22FF; font-weight: bold\">=</span><span style=\"color: #BA2121\">&quot;float32&quot;</span>)) <span style=\"color: #AA22FF; font-weight: bold\">-&gt;</span> R<span style=\"color: #AA22FF; font-weight: bold\">.</span>Tensor((<span style=\"color: #008000\">1</span>, <span style=\"color: #008000\">128</span>), dtype<span style=\"color: #AA22FF; font-weight: bold\">=</span><span style=\"color: #BA2121\">&quot;float32&quot;</span>):\n",
              "        cls <span style=\"color: #AA22FF; font-weight: bold\">=</span> Module\n",
              "        <span style=\"color: #008000; font-weight: bold\">with</span> R<span style=\"color: #AA22FF; font-weight: bold\">.</span>dataflow():\n",
              "            lv <span style=\"color: #AA22FF; font-weight: bold\">=</span> R<span style=\"color: #AA22FF; font-weight: bold\">.</span>call_tir(cls<span style=\"color: #AA22FF; font-weight: bold\">.</span>te_matmul, (x, metadata[<span style=\"color: #BA2121\">&quot;relax.expr.Constant&quot;</span>][<span style=\"color: #008000\">0</span>]), out_sinfo<span style=\"color: #AA22FF; font-weight: bold\">=</span>R<span style=\"color: #AA22FF; font-weight: bold\">.</span>Tensor((<span style=\"color: #008000\">1</span>, <span style=\"color: #008000\">128</span>), dtype<span style=\"color: #AA22FF; font-weight: bold\">=</span><span style=\"color: #BA2121\">&quot;float32&quot;</span>))\n",
              "            lv1 <span style=\"color: #AA22FF; font-weight: bold\">=</span> R<span style=\"color: #AA22FF; font-weight: bold\">.</span>call_tir(cls<span style=\"color: #AA22FF; font-weight: bold\">.</span>te_relu, (lv,), out_sinfo<span style=\"color: #AA22FF; font-weight: bold\">=</span>R<span style=\"color: #AA22FF; font-weight: bold\">.</span>Tensor((<span style=\"color: #008000\">1</span>, <span style=\"color: #008000\">128</span>), dtype<span style=\"color: #AA22FF; font-weight: bold\">=</span><span style=\"color: #BA2121\">&quot;float32&quot;</span>))\n",
              "            gv: R<span style=\"color: #AA22FF; font-weight: bold\">.</span>Tensor((<span style=\"color: #008000\">1</span>, <span style=\"color: #008000\">128</span>), dtype<span style=\"color: #AA22FF; font-weight: bold\">=</span><span style=\"color: #BA2121\">&quot;float32&quot;</span>) <span style=\"color: #AA22FF; font-weight: bold\">=</span> lv1\n",
              "            R<span style=\"color: #AA22FF; font-weight: bold\">.</span>output(gv)\n",
              "        <span style=\"color: #008000; font-weight: bold\">return</span> lv1\n",
              "\n",
              "<span style=\"color: #007979; font-style: italic\"># Metadata omitted. Use show_meta=True in script() method to show it.</span>\n",
              "</pre></div>\n"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "e9gpsR0oov9Q"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}