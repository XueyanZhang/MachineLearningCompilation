{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPzw/j7DVQB5ma6iXJdkam/",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/XueyanZhang/MachineLearningCompilation/blob/master/5_End2End_Auto_Opt.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# End to End Module Automatic Optimization\n",
        "\n",
        "Put everything we learned so far together.\n",
        "optimize the performance of the MLP example."
      ],
      "metadata": {
        "id": "Y8nbGIUUsmZq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!python3 -m  pip install mlc-ai-nightly -f https://mlc.ai/wheels\n",
        "\n",
        "import numpy as np\n",
        "import torch\n",
        "import torchvision\n",
        "import tvm\n",
        "from tvm import relax\n",
        "from tvm.ir.module import IRModule\n",
        "from tvm.script import relax as R\n",
        "from tvm.script import tir as T"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UhD5qe8rtDbO",
        "outputId": "5b63a5a8-c495-4de3-8bf1-6f563642e490"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Looking in links: https://mlc.ai/wheels\n",
            "Collecting mlc-ai-nightly\n",
            "  Downloading https://github.com/mlc-ai/utils/releases/download/v0.9.dev0/mlc_ai_nightly-0.12.dev871%2Bg838ec67e9-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (52.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m52.1/52.1 MB\u001b[0m \u001b[31m13.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: cloudpickle in /usr/local/lib/python3.10/dist-packages (from mlc-ai-nightly) (2.2.1)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from mlc-ai-nightly) (5.9.5)\n",
            "Requirement already satisfied: tornado in /usr/local/lib/python3.10/dist-packages (from mlc-ai-nightly) (6.2)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from mlc-ai-nightly) (1.10.1)\n",
            "Requirement already satisfied: attrs in /usr/local/lib/python3.10/dist-packages (from mlc-ai-nightly) (23.1.0)\n",
            "Requirement already satisfied: numpy<=1.23 in /usr/local/lib/python3.10/dist-packages (from mlc-ai-nightly) (1.22.4)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.10/dist-packages (from mlc-ai-nightly) (4.4.2)\n",
            "Installing collected packages: mlc-ai-nightly\n",
            "Successfully installed mlc-ai-nightly-0.12.dev871+g838ec67e9\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_data = torchvision.datasets.FashionMNIST(\n",
        "    root='data',\n",
        "    train=False,\n",
        "    download=True,\n",
        "    transform=torchvision.transforms.ToTensor()\n",
        ")\n",
        "test_loader = torch.utils.data.DataLoader(test_data, batch_size=1, shuffle=True)\n",
        "class_names = ['T-shirt/top', 'Trouser', 'Pullover', 'Dress', 'Coat',\n",
        "               'Sandal', 'Shirt', 'Sneaker', 'Bag', 'Ankle boot']\n",
        "\n",
        "img, label = next(iter(test_loader))\n",
        "img = img.reshape(1, 28, 28).numpy()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g9sgQh5NtLY6",
        "outputId": "fe36a638-0603-4e13-92fa-980587418458"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-images-idx3-ubyte.gz\n",
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-images-idx3-ubyte.gz to data/FashionMNIST/raw/train-images-idx3-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 26421880/26421880 [00:01<00:00, 18714816.77it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting data/FashionMNIST/raw/train-images-idx3-ubyte.gz to data/FashionMNIST/raw\n",
            "\n",
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-labels-idx1-ubyte.gz\n",
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-labels-idx1-ubyte.gz to data/FashionMNIST/raw/train-labels-idx1-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 29515/29515 [00:00<00:00, 334644.07it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting data/FashionMNIST/raw/train-labels-idx1-ubyte.gz to data/FashionMNIST/raw\n",
            "\n",
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-images-idx3-ubyte.gz\n",
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-images-idx3-ubyte.gz to data/FashionMNIST/raw/t10k-images-idx3-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 4422102/4422102 [00:00<00:00, 6189069.98it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting data/FashionMNIST/raw/t10k-images-idx3-ubyte.gz to data/FashionMNIST/raw\n",
            "\n",
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-labels-idx1-ubyte.gz\n",
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-labels-idx1-ubyte.gz to data/FashionMNIST/raw/t10k-labels-idx1-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 5148/5148 [00:00<00:00, 23217502.14it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting data/FashionMNIST/raw/t10k-labels-idx1-ubyte.gz to data/FashionMNIST/raw\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.figure()\n",
        "plt.imshow(img[0])\n",
        "plt.colorbar()\n",
        "plt.grid(False)\n",
        "plt.show()\n",
        "\n",
        "print(f\"class is {class_names[label[0]]}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 452
        },
        "id": "3QPccQTnuDqW",
        "outputId": "ed870acc-2a35-4231-9dba-3ac860906955"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "class is Sneaker\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# download pre-packed (trained) parameters\n",
        "# Hide outputs\n",
        "!wget -nc https://github.com/mlc-ai/web-data/raw/main/models/fasionmnist_mlp_params.pkl"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_fjF385RvMlM",
        "outputId": "2157525f-2b07-4378-daec-c3aae105faec"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2023-05-06 18:43:29--  https://github.com/mlc-ai/web-data/raw/main/models/fasionmnist_mlp_params.pkl\n",
            "Resolving github.com (github.com)... 140.82.114.3\n",
            "Connecting to github.com (github.com)|140.82.114.3|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://raw.githubusercontent.com/mlc-ai/web-data/main/models/fasionmnist_mlp_params.pkl [following]\n",
            "--2023-05-06 18:43:29--  https://raw.githubusercontent.com/mlc-ai/web-data/main/models/fasionmnist_mlp_params.pkl\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 407396 (398K) [application/octet-stream]\n",
            "Saving to: ‘fasionmnist_mlp_params.pkl’\n",
            "\n",
            "fasionmnist_mlp_par 100%[===================>] 397.85K  --.-KB/s    in 0.007s  \n",
            "\n",
            "2023-05-06 18:43:29 (56.3 MB/s) - ‘fasionmnist_mlp_params.pkl’ saved [407396/407396]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pickle as pkl\n",
        "\n",
        "mlp_params = pkl.load(open(\"fasionmnist_mlp_params.pkl\", \"rb\"))\n",
        "nd_params = {k: tvm.nd.array(v) for k, v in mlp_params.items()}\n",
        "\n",
        "# image input to network\n",
        "data_nd = tvm.nd.array(img.reshape(1, 784))"
      ],
      "metadata": {
        "id": "vzoRDaQ3vTIe"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tvm.script.ir_builder.relax.ir import dtype\n",
        "# use mixture module (1 TensorIR + 2 Torch func)\n",
        "f32 = \"float32\"\n",
        "@tvm.script.ir_module\n",
        "class MyModuleMixture:\n",
        "    @T.prim_func\n",
        "    def linear0(X: T.Buffer((1, 784), f32),\n",
        "                W: T.Buffer((128, 784), f32),\n",
        "                B: T.Buffer((128), f32),\n",
        "                Z: T.Buffer((1, 128), f32)):\n",
        "        T.func_attr({\"global_symbol\": \"linear0\", \"tir.noalias\": True})\n",
        "        Y = T.alloc_buffer((1, 128), f32)\n",
        "        for i, j, k in T.grid(1, 128, 784):\n",
        "            with T.block(\"Y\"):\n",
        "                vi, vj, vk = T.axis.remap(\"SSR\", [i, j, k])\n",
        "                with T.init():\n",
        "                    Y[vi, vj] = T.float32(0)\n",
        "                Y[vi, vj] = Y[vi, vj] + X[vi, vk] * W[vj, vk]\n",
        "        \n",
        "        for i, j in T.grid(1, 128):\n",
        "            with T.block(\"Z\"):\n",
        "                vi, vj = T.axis.remap(\"SS\", [i, j])\n",
        "                Z[vi, vj] = Y[vi, vj] + B[vj]\n",
        "\n",
        "    @R.function\n",
        "    def main(x: R.Tensor((1, 784), f32),\n",
        "             w0: R.Tensor((128, 784), f32),\n",
        "             b0: R.Tensor((128, ), f32),\n",
        "             w1: R.Tensor((10, 128), f32),\n",
        "             b1: R.Tensor((10,), f32)):\n",
        "        with R.dataflow():\n",
        "            lv0 = R.call_dps_packed(\"linear0\", (x, w0, b0), R.Tensor((1, 128), dtype=f32))\n",
        "            lv1 = R.call_dps_packed(\"env.relu\", (lv0, ), R.Tensor((1, 128), dtype=f32))\n",
        "            out = R.call_dps_packed(\"env.linear\", (lv1, w1, b1), R.Tensor((1, 10), dtype=f32))\n",
        "            R.output(out)\n",
        "        return out\n",
        "\n",
        "# register external torch funcs\n",
        "@tvm.register_func(\"env.linear\", override=True)\n",
        "def torch_linear(x: tvm.nd.NDArray,\n",
        "                 w: tvm.nd.NDArray,\n",
        "                 b: tvm.nd.NDArray,\n",
        "                 z: tvm.nd.NDArray):\n",
        "    x_torch = torch.from_dlpack(x)\n",
        "    w_torch = torch.from_dlpack(w)\n",
        "    b_torch = torch.from_dlpack(b)\n",
        "    z_torch = torch.from_dlpack(z)\n",
        "    torch.mm(x_torch, w_torch.T, out=z_torch)\n",
        "    torch.add(z_torch, b_torch, out=z_torch)\n",
        "\n",
        "@tvm.register_func(\"env.relu\", override=True)\n",
        "def torch_relu(x: tvm.nd.NDArray,\n",
        "               out: tvm.nd.NDArray):\n",
        "    x_torch = torch.from_dlpack(x)\n",
        "    out_torch = torch.from_dlpack(out)\n",
        "    torch.maximum(x_torch, torch.Tensor([0.0]), out=out_torch)"
      ],
      "metadata": {
        "id": "1gKD4OOkv7YN"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# bind parameters\n",
        "MyModuleWithParams = relax.transform.BindParams(\"main\", nd_params)(MyModuleMixture)\n",
        "\n",
        "# build\n",
        "ex = relax.build(MyModuleWithParams, target='llvm')\n",
        "vm = relax.VirtualMachine(ex, tvm.cpu())\n",
        "\n",
        "# run\n",
        "nd_res = vm[\"main\"](data_nd)\n",
        "\n",
        "# result\n",
        "pred_kind = np.argmax(nd_res.numpy(), axis=1)\n",
        "print(\"my module with params prediction:\", class_names[pred_kind[0]])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_yWgBdFVX_c0",
        "outputId": "022de753-319a-4945-dbba-6f70bf5c50d6"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "my module with params prediction: Sneaker\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# evaluate runtime (average on 100 trails)\n",
        "ftimer = vm.module.time_evaluator(\"main\", tvm.cpu(), number=100)\n",
        "print(\"my module with params time cost\", ftimer(data_nd).mean * 1000, \"ms\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XAsmTDB4ZsjN",
        "outputId": "03b828e1-f2b0-4ee4-cc6e-0e8916d0ae4f"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "my module with params time cost 0.24304182 ms\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Auto Tune\n",
        "\n",
        "now with MLP end to end module setup, we can apply auto tune.\n",
        "\n",
        "we have one tensor ir to tune."
      ],
      "metadata": {
        "id": "mmDHZ6JnaJ9m"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# get linear0\n",
        "mod_linear = tvm.IRModule.from_expr(MyModuleMixture[\"linear0\"].with_attr(\"global_symbol\", \"main\"))\n",
        "mod_linear.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 506
        },
        "id": "mo2cdTriaYUU",
        "outputId": "5df81ce9-1fbe-4f8c-8405-3cd0ac08b2a8"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/tvm/script/highlight.py:117: UserWarning: No module named 'black'\n",
            "To print formatted TVM script, please install the formatter 'Black':\n",
            "/usr/bin/python3 -m pip install \"black==22.3.0\" --upgrade --user\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<div class=\"highlight\" style=\"background: \"><pre style=\"line-height: 125%;\"><span></span><span style=\"color: #007979; font-style: italic\"># from tvm.script import ir as I</span>\n",
              "<span style=\"color: #007979; font-style: italic\"># from tvm.script import tir as T</span>\n",
              "\n",
              "<span style=\"color: #AA22FF\">@I</span><span style=\"color: #AA22FF; font-weight: bold\">.</span>ir_module\n",
              "<span style=\"color: #008000; font-weight: bold\">class</span> <span style=\"color: #0000FF; font-weight: bold\">Module</span>:\n",
              "    <span style=\"color: #AA22FF\">@T</span><span style=\"color: #AA22FF; font-weight: bold\">.</span>prim_func\n",
              "    <span style=\"color: #008000; font-weight: bold\">def</span> <span style=\"color: #0000FF\">main</span>(X: T<span style=\"color: #AA22FF; font-weight: bold\">.</span>Buffer((<span style=\"color: #008000\">1</span>, <span style=\"color: #008000\">784</span>), <span style=\"color: #BA2121\">&quot;float32&quot;</span>), W: T<span style=\"color: #AA22FF; font-weight: bold\">.</span>Buffer((<span style=\"color: #008000\">128</span>, <span style=\"color: #008000\">784</span>), <span style=\"color: #BA2121\">&quot;float32&quot;</span>), B: T<span style=\"color: #AA22FF; font-weight: bold\">.</span>Buffer((<span style=\"color: #008000\">128</span>,), <span style=\"color: #BA2121\">&quot;float32&quot;</span>), Z: T<span style=\"color: #AA22FF; font-weight: bold\">.</span>Buffer((<span style=\"color: #008000\">1</span>, <span style=\"color: #008000\">128</span>), <span style=\"color: #BA2121\">&quot;float32&quot;</span>)):\n",
              "        T<span style=\"color: #AA22FF; font-weight: bold\">.</span>func_attr({<span style=\"color: #BA2121\">&quot;global_symbol&quot;</span>: <span style=\"color: #BA2121\">&quot;main&quot;</span>, <span style=\"color: #BA2121\">&quot;tir.noalias&quot;</span>: T<span style=\"color: #AA22FF; font-weight: bold\">.</span>bool(<span style=\"color: #008000; font-weight: bold\">True</span>)})\n",
              "        <span style=\"color: #007979; font-style: italic\"># with T.block(&quot;root&quot;):</span>\n",
              "        Y <span style=\"color: #AA22FF; font-weight: bold\">=</span> T<span style=\"color: #AA22FF; font-weight: bold\">.</span>alloc_buffer((<span style=\"color: #008000\">1</span>, <span style=\"color: #008000\">128</span>))\n",
              "        <span style=\"color: #008000; font-weight: bold\">for</span> i, j, k <span style=\"color: #008000; font-weight: bold\">in</span> T<span style=\"color: #AA22FF; font-weight: bold\">.</span>grid(<span style=\"color: #008000\">1</span>, <span style=\"color: #008000\">128</span>, <span style=\"color: #008000\">784</span>):\n",
              "            <span style=\"color: #008000; font-weight: bold\">with</span> T<span style=\"color: #AA22FF; font-weight: bold\">.</span>block(<span style=\"color: #BA2121\">&quot;Y&quot;</span>):\n",
              "                vi, vj, vk <span style=\"color: #AA22FF; font-weight: bold\">=</span> T<span style=\"color: #AA22FF; font-weight: bold\">.</span>axis<span style=\"color: #AA22FF; font-weight: bold\">.</span>remap(<span style=\"color: #BA2121\">&quot;SSR&quot;</span>, [i, j, k])\n",
              "                T<span style=\"color: #AA22FF; font-weight: bold\">.</span>reads(X[vi, vk], W[vj, vk])\n",
              "                T<span style=\"color: #AA22FF; font-weight: bold\">.</span>writes(Y[vi, vj])\n",
              "                <span style=\"color: #008000; font-weight: bold\">with</span> T<span style=\"color: #AA22FF; font-weight: bold\">.</span>init():\n",
              "                    Y[vi, vj] <span style=\"color: #AA22FF; font-weight: bold\">=</span> T<span style=\"color: #AA22FF; font-weight: bold\">.</span>float32(<span style=\"color: #008000\">0</span>)\n",
              "                Y[vi, vj] <span style=\"color: #AA22FF; font-weight: bold\">=</span> Y[vi, vj] <span style=\"color: #AA22FF; font-weight: bold\">+</span> X[vi, vk] <span style=\"color: #AA22FF; font-weight: bold\">*</span> W[vj, vk]\n",
              "        <span style=\"color: #008000; font-weight: bold\">for</span> i, j <span style=\"color: #008000; font-weight: bold\">in</span> T<span style=\"color: #AA22FF; font-weight: bold\">.</span>grid(<span style=\"color: #008000\">1</span>, <span style=\"color: #008000\">128</span>):\n",
              "            <span style=\"color: #008000; font-weight: bold\">with</span> T<span style=\"color: #AA22FF; font-weight: bold\">.</span>block(<span style=\"color: #BA2121\">&quot;Z&quot;</span>):\n",
              "                vi, vj <span style=\"color: #AA22FF; font-weight: bold\">=</span> T<span style=\"color: #AA22FF; font-weight: bold\">.</span>axis<span style=\"color: #AA22FF; font-weight: bold\">.</span>remap(<span style=\"color: #BA2121\">&quot;SS&quot;</span>, [i, j])\n",
              "                T<span style=\"color: #AA22FF; font-weight: bold\">.</span>reads(Y[vi, vj], B[vj])\n",
              "                T<span style=\"color: #AA22FF; font-weight: bold\">.</span>writes(Z[vi, vj])\n",
              "                Z[vi, vj] <span style=\"color: #AA22FF; font-weight: bold\">=</span> Y[vi, vj] <span style=\"color: #AA22FF; font-weight: bold\">+</span> B[vj]\n",
              "</pre></div>\n"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tvm import meta_schedule as ms\n",
        "\n",
        "database = ms.tune_tir(\n",
        "    mod=mod_linear,\n",
        "    target=\"llvm --num-cores=1\",\n",
        "    max_trials_global=64,\n",
        "    num_trials_per_iter=64,\n",
        "    work_dir=\"./tune_tmp\",\n",
        "    task_name='main'\n",
        ")\n",
        "sch = ms.tir_integration.compile_tir(database, mod_linear, \"llvm --num-cores=1\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GfqiCsVIcdGL",
        "outputId": "d1732c91-0213-4c20-84b4-b6d1943b03cd"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2023-05-06 19:04:42 [INFO] Logging directory: ./tune_tmp/logs\n",
            "2023-05-06 19:04:58 [INFO] LocalBuilder: max_workers = 1\n",
            "2023-05-06 19:05:00 [INFO] LocalRunner: max_workers = 1\n",
            "2023-05-06 19:05:01 [INFO] [task_scheduler.cc:159] Initializing Task #0: \"main\"\n",
            "2023-05-06 19:05:01 [INFO] [task_scheduler.cc:180] TaskScheduler picks Task #0: \"main\"\n",
            "2023-05-06 19:05:06 [INFO] [task_scheduler.cc:193] Sending 64 sample(s) to builder\n",
            "2023-05-06 19:05:58 [INFO] [task_scheduler.cc:195] Sending 64 sample(s) to runner\n",
            "2023-05-06 19:06:10 [DEBUG] XGB iter   0: tr-p-rmse: 0.370889\ttr-a-peak@32: 1.000000\ttr-rmse: 0.269308\ttr-rmse: 0.269308\n",
            "2023-05-06 19:06:10 [DEBUG] XGB iter  25: tr-p-rmse: 0.036241\ttr-a-peak@32: 1.000000\ttr-rmse: 0.334572\ttr-rmse: 0.334572\n",
            "2023-05-06 19:06:10 [DEBUG] XGB iter  50: tr-p-rmse: 0.036106\ttr-a-peak@32: 1.000000\ttr-rmse: 0.334861\ttr-rmse: 0.334861\n",
            "2023-05-06 19:06:10 [DEBUG] XGB iter  75: tr-p-rmse: 0.036106\ttr-a-peak@32: 1.000000\ttr-rmse: 0.334861\ttr-rmse: 0.334861\n",
            "2023-05-06 19:06:10 [DEBUG] XGB stopped. Best iteration: [38] tr-p-rmse:0.03611\ttr-a-peak@32:1.00000\ttr-rmse:0.33486\ttr-rmse:0.33486 \n",
            "2023-05-06 19:06:10 [INFO] [task_scheduler.cc:237] [Updated] Task #0: \"main\"\n",
            "2023-05-06 19:06:10 [INFO] [task_scheduler.cc:320] \n",
            " ID | Name |   FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Done \n",
            "-----------------------------------------------------------------------------------------------------\n",
            "  0 | main | 200832 |      1 |         9.9781 |      20.1274 |               20.1274 |     64 |      \n",
            "-----------------------------------------------------------------------------------------------------\n",
            "Total trials: 64\n",
            "Total latency (us): 20.1274\n",
            "\n",
            "2023-05-06 19:06:10 [INFO] [task_scheduler.cc:260] Task #0 has finished. Remaining task(s): 0\n",
            "2023-05-06 19:06:10 [INFO] [task_scheduler.cc:320] \n",
            " ID | Name |   FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Done \n",
            "-----------------------------------------------------------------------------------------------------\n",
            "  0 | main | 200832 |      1 |         9.9781 |      20.1274 |               20.1274 |     64 |    Y \n",
            "-----------------------------------------------------------------------------------------------------\n",
            "Total trials: 64\n",
            "Total latency (us): 20.1274\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# linear0 is tuned. see the tunings\n",
        "sch.trace"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TqRzLMQRdYrv",
        "outputId": "fde2f496-3ddb-45d1-c32e-28f010b63ce2"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "# from tvm import tir\n",
              "def apply_trace(sch: tir.Schedule) -> None:\n",
              "  b0 = sch.get_block(name=\"Y\", func_name=\"main\")\n",
              "  b1 = sch.get_block(name=\"root\", func_name=\"main\")\n",
              "  sch.annotate(block_or_loop=b0, ann_key=\"meta_schedule.tiling_structure\", ann_val=\"SSRSRS\")\n",
              "  l2, l3, l4 = sch.get_loops(block=b0)\n",
              "  v5, v6, v7, v8 = sch.sample_perfect_tile(loop=l2, n=4, max_innermost_factor=64, decision=[1, 1, 1, 1])\n",
              "  l9, l10, l11, l12 = sch.split(loop=l2, factors=[v5, v6, v7, v8], preserve_unit_iters=True)\n",
              "  v13, v14, v15, v16 = sch.sample_perfect_tile(loop=l3, n=4, max_innermost_factor=64, decision=[1, 16, 8, 1])\n",
              "  l17, l18, l19, l20 = sch.split(loop=l3, factors=[v13, v14, v15, v16], preserve_unit_iters=True)\n",
              "  v21, v22 = sch.sample_perfect_tile(loop=l4, n=2, max_innermost_factor=64, decision=[112, 7])\n",
              "  l23, l24 = sch.split(loop=l4, factors=[v21, v22], preserve_unit_iters=True)\n",
              "  sch.reorder(l9, l17, l10, l18, l23, l11, l19, l24, l12, l20)\n",
              "  b25, = sch.get_consumers(block=b0)\n",
              "  sch.reverse_compute_at(block=b25, loop=l18, preserve_unit_loops=True, index=-1)\n",
              "  sch.annotate(block_or_loop=b1, ann_key=\"meta_schedule.parallel\", ann_val=16)\n",
              "  sch.annotate(block_or_loop=b1, ann_key=\"meta_schedule.vectorize\", ann_val=64)\n",
              "  v26 = sch.sample_categorical(candidates=[0, 16, 64, 512], probs=[0.25, 0.25, 0.25, 0.25], decision=3)\n",
              "  sch.annotate(block_or_loop=b1, ann_key=\"meta_schedule.unroll_explicit\", ann_val=v26)\n",
              "  sch.enter_postproc()\n",
              "  b27 = sch.get_block(name=\"root\", func_name=\"main\")\n",
              "  sch.unannotate(block_or_loop=b27, ann_key=\"meta_schedule.parallel\")\n",
              "  sch.unannotate(block_or_loop=b27, ann_key=\"meta_schedule.vectorize\")\n",
              "  sch.unannotate(block_or_loop=b27, ann_key=\"meta_schedule.unroll_explicit\")\n",
              "  b28, b29 = sch.get_child_blocks(b27)\n",
              "  l30, l31, l32, l33, l34, l35, l36, l37, l38, l39 = sch.get_loops(block=b28)\n",
              "  l40 = sch.fuse(l30, l31, l32, l33, preserve_unit_iters=True)\n",
              "  sch.parallel(loop=l40)\n",
              "  sch.annotate(block_or_loop=l40, ann_key=\"pragma_auto_unroll_max_step\", ann_val=512)\n",
              "  sch.annotate(block_or_loop=l40, ann_key=\"pragma_unroll_explicit\", ann_val=1)\n",
              "  l41, l42, l43 = sch.get_loops(block=b29)\n",
              "  l44 = sch.fuse(l43, preserve_unit_iters=True)\n",
              "  sch.vectorize(loop=l44)\n",
              "  b45 = sch.get_block(name=\"Y\", func_name=\"main\")\n",
              "  l46, l47, l48, l49, l50, l51, l52 = sch.get_loops(block=b45)\n",
              "  b53 = sch.decompose_reduction(block=b45, loop=l47)"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# see the tensor ir\n",
        "sch.mod.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 716
        },
        "id": "W7suo2cAdicv",
        "outputId": "ef317baa-f9f6-4c60-a2a7-e78c06b3e80e"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/tvm/script/highlight.py:117: UserWarning: No module named 'black'\n",
            "To print formatted TVM script, please install the formatter 'Black':\n",
            "/usr/bin/python3 -m pip install \"black==22.3.0\" --upgrade --user\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<div class=\"highlight\" style=\"background: \"><pre style=\"line-height: 125%;\"><span></span><span style=\"color: #007979; font-style: italic\"># from tvm.script import ir as I</span>\n",
              "<span style=\"color: #007979; font-style: italic\"># from tvm.script import tir as T</span>\n",
              "\n",
              "<span style=\"color: #AA22FF\">@I</span><span style=\"color: #AA22FF; font-weight: bold\">.</span>ir_module\n",
              "<span style=\"color: #008000; font-weight: bold\">class</span> <span style=\"color: #0000FF; font-weight: bold\">Module</span>:\n",
              "    <span style=\"color: #AA22FF\">@T</span><span style=\"color: #AA22FF; font-weight: bold\">.</span>prim_func\n",
              "    <span style=\"color: #008000; font-weight: bold\">def</span> <span style=\"color: #0000FF\">main</span>(X: T<span style=\"color: #AA22FF; font-weight: bold\">.</span>Buffer((<span style=\"color: #008000\">1</span>, <span style=\"color: #008000\">784</span>), <span style=\"color: #BA2121\">&quot;float32&quot;</span>), W: T<span style=\"color: #AA22FF; font-weight: bold\">.</span>Buffer((<span style=\"color: #008000\">128</span>, <span style=\"color: #008000\">784</span>), <span style=\"color: #BA2121\">&quot;float32&quot;</span>), B: T<span style=\"color: #AA22FF; font-weight: bold\">.</span>Buffer((<span style=\"color: #008000\">128</span>,), <span style=\"color: #BA2121\">&quot;float32&quot;</span>), Z: T<span style=\"color: #AA22FF; font-weight: bold\">.</span>Buffer((<span style=\"color: #008000\">1</span>, <span style=\"color: #008000\">128</span>), <span style=\"color: #BA2121\">&quot;float32&quot;</span>)):\n",
              "        T<span style=\"color: #AA22FF; font-weight: bold\">.</span>func_attr({<span style=\"color: #BA2121\">&quot;global_symbol&quot;</span>: <span style=\"color: #BA2121\">&quot;main&quot;</span>, <span style=\"color: #BA2121\">&quot;tir.noalias&quot;</span>: T<span style=\"color: #AA22FF; font-weight: bold\">.</span>bool(<span style=\"color: #008000; font-weight: bold\">True</span>)})\n",
              "        <span style=\"color: #007979; font-style: italic\"># with T.block(&quot;root&quot;):</span>\n",
              "        Y <span style=\"color: #AA22FF; font-weight: bold\">=</span> T<span style=\"color: #AA22FF; font-weight: bold\">.</span>alloc_buffer((<span style=\"color: #008000\">1</span>, <span style=\"color: #008000\">128</span>))\n",
              "        <span style=\"color: #008000; font-weight: bold\">for</span> i_0_j_0_i_1_j_1_fused <span style=\"color: #008000; font-weight: bold\">in</span> T<span style=\"color: #AA22FF; font-weight: bold\">.</span>parallel(<span style=\"color: #008000\">16</span>, annotations<span style=\"color: #AA22FF; font-weight: bold\">=</span>{<span style=\"color: #BA2121\">&quot;pragma_auto_unroll_max_step&quot;</span>: <span style=\"color: #008000\">512</span>, <span style=\"color: #BA2121\">&quot;pragma_unroll_explicit&quot;</span>: <span style=\"color: #008000\">1</span>}):\n",
              "            <span style=\"color: #008000; font-weight: bold\">for</span> i_2_init, j_2_init, i_3_init, j_3_init <span style=\"color: #008000; font-weight: bold\">in</span> T<span style=\"color: #AA22FF; font-weight: bold\">.</span>grid(<span style=\"color: #008000\">1</span>, <span style=\"color: #008000\">8</span>, <span style=\"color: #008000\">1</span>, <span style=\"color: #008000\">1</span>):\n",
              "                <span style=\"color: #008000; font-weight: bold\">with</span> T<span style=\"color: #AA22FF; font-weight: bold\">.</span>block(<span style=\"color: #BA2121\">&quot;Y_init&quot;</span>):\n",
              "                    vi <span style=\"color: #AA22FF; font-weight: bold\">=</span> T<span style=\"color: #AA22FF; font-weight: bold\">.</span>axis<span style=\"color: #AA22FF; font-weight: bold\">.</span>spatial(<span style=\"color: #008000\">1</span>, i_2_init <span style=\"color: #AA22FF; font-weight: bold\">+</span> i_3_init)\n",
              "                    vj <span style=\"color: #AA22FF; font-weight: bold\">=</span> T<span style=\"color: #AA22FF; font-weight: bold\">.</span>axis<span style=\"color: #AA22FF; font-weight: bold\">.</span>spatial(<span style=\"color: #008000\">128</span>, i_0_j_0_i_1_j_1_fused <span style=\"color: #AA22FF; font-weight: bold\">*</span> <span style=\"color: #008000\">8</span> <span style=\"color: #AA22FF; font-weight: bold\">+</span> j_2_init <span style=\"color: #AA22FF; font-weight: bold\">+</span> j_3_init)\n",
              "                    T<span style=\"color: #AA22FF; font-weight: bold\">.</span>reads()\n",
              "                    T<span style=\"color: #AA22FF; font-weight: bold\">.</span>writes(Y[vi, vj])\n",
              "                    T<span style=\"color: #AA22FF; font-weight: bold\">.</span>block_attr({<span style=\"color: #BA2121\">&quot;meta_schedule.tiling_structure&quot;</span>: <span style=\"color: #BA2121\">&quot;SSRSRS&quot;</span>})\n",
              "                    Y[vi, vj] <span style=\"color: #AA22FF; font-weight: bold\">=</span> T<span style=\"color: #AA22FF; font-weight: bold\">.</span>float32(<span style=\"color: #008000\">0</span>)\n",
              "            <span style=\"color: #008000; font-weight: bold\">for</span> k_0, i_2, j_2, k_1, i_3, j_3 <span style=\"color: #008000; font-weight: bold\">in</span> T<span style=\"color: #AA22FF; font-weight: bold\">.</span>grid(<span style=\"color: #008000\">112</span>, <span style=\"color: #008000\">1</span>, <span style=\"color: #008000\">8</span>, <span style=\"color: #008000\">7</span>, <span style=\"color: #008000\">1</span>, <span style=\"color: #008000\">1</span>):\n",
              "                <span style=\"color: #008000; font-weight: bold\">with</span> T<span style=\"color: #AA22FF; font-weight: bold\">.</span>block(<span style=\"color: #BA2121\">&quot;Y_update&quot;</span>):\n",
              "                    vi <span style=\"color: #AA22FF; font-weight: bold\">=</span> T<span style=\"color: #AA22FF; font-weight: bold\">.</span>axis<span style=\"color: #AA22FF; font-weight: bold\">.</span>spatial(<span style=\"color: #008000\">1</span>, i_2 <span style=\"color: #AA22FF; font-weight: bold\">+</span> i_3)\n",
              "                    vj <span style=\"color: #AA22FF; font-weight: bold\">=</span> T<span style=\"color: #AA22FF; font-weight: bold\">.</span>axis<span style=\"color: #AA22FF; font-weight: bold\">.</span>spatial(<span style=\"color: #008000\">128</span>, i_0_j_0_i_1_j_1_fused <span style=\"color: #AA22FF; font-weight: bold\">*</span> <span style=\"color: #008000\">8</span> <span style=\"color: #AA22FF; font-weight: bold\">+</span> j_2 <span style=\"color: #AA22FF; font-weight: bold\">+</span> j_3)\n",
              "                    vk <span style=\"color: #AA22FF; font-weight: bold\">=</span> T<span style=\"color: #AA22FF; font-weight: bold\">.</span>axis<span style=\"color: #AA22FF; font-weight: bold\">.</span>reduce(<span style=\"color: #008000\">784</span>, k_0 <span style=\"color: #AA22FF; font-weight: bold\">*</span> <span style=\"color: #008000\">7</span> <span style=\"color: #AA22FF; font-weight: bold\">+</span> k_1)\n",
              "                    T<span style=\"color: #AA22FF; font-weight: bold\">.</span>reads(Y[vi, vj], X[vi, vk], W[vj, vk])\n",
              "                    T<span style=\"color: #AA22FF; font-weight: bold\">.</span>writes(Y[vi, vj])\n",
              "                    T<span style=\"color: #AA22FF; font-weight: bold\">.</span>block_attr({<span style=\"color: #BA2121\">&quot;meta_schedule.tiling_structure&quot;</span>: <span style=\"color: #BA2121\">&quot;SSRSRS&quot;</span>})\n",
              "                    Y[vi, vj] <span style=\"color: #AA22FF; font-weight: bold\">=</span> Y[vi, vj] <span style=\"color: #AA22FF; font-weight: bold\">+</span> X[vi, vk] <span style=\"color: #AA22FF; font-weight: bold\">*</span> W[vj, vk]\n",
              "            <span style=\"color: #008000; font-weight: bold\">for</span> ax0 <span style=\"color: #008000; font-weight: bold\">in</span> range(<span style=\"color: #008000\">1</span>):\n",
              "                <span style=\"color: #008000; font-weight: bold\">for</span> ax1_fused <span style=\"color: #008000; font-weight: bold\">in</span> T<span style=\"color: #AA22FF; font-weight: bold\">.</span>vectorized(<span style=\"color: #008000\">8</span>):\n",
              "                    <span style=\"color: #008000; font-weight: bold\">with</span> T<span style=\"color: #AA22FF; font-weight: bold\">.</span>block(<span style=\"color: #BA2121\">&quot;Z&quot;</span>):\n",
              "                        vi <span style=\"color: #AA22FF; font-weight: bold\">=</span> T<span style=\"color: #AA22FF; font-weight: bold\">.</span>axis<span style=\"color: #AA22FF; font-weight: bold\">.</span>spatial(<span style=\"color: #008000\">1</span>, ax0)\n",
              "                        vj <span style=\"color: #AA22FF; font-weight: bold\">=</span> T<span style=\"color: #AA22FF; font-weight: bold\">.</span>axis<span style=\"color: #AA22FF; font-weight: bold\">.</span>spatial(<span style=\"color: #008000\">128</span>, i_0_j_0_i_1_j_1_fused <span style=\"color: #AA22FF; font-weight: bold\">*</span> <span style=\"color: #008000\">8</span> <span style=\"color: #AA22FF; font-weight: bold\">+</span> ax1_fused)\n",
              "                        T<span style=\"color: #AA22FF; font-weight: bold\">.</span>reads(Y[vi, vj], B[vj])\n",
              "                        T<span style=\"color: #AA22FF; font-weight: bold\">.</span>writes(Z[vi, vj])\n",
              "                        Z[vi, vj] <span style=\"color: #AA22FF; font-weight: bold\">=</span> Y[vi, vj] <span style=\"color: #AA22FF; font-weight: bold\">+</span> B[vj]\n",
              "</pre></div>\n"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# done tuning. replace linear0 in our module\n",
        "MyModuleWithParamsTuned = relax.transform.BindParams(\"main\", nd_params)(MyModuleMixture)\n",
        "new_linear0 = sch.mod[\"main\"].with_attr(\"global_symbol\", \"linear0\")\n",
        "gv = MyModuleWithParamsTuned.get_global_var(\"linear0\")\n",
        "MyModuleWithParamsTuned.update_func(gv, new_linear0)\n",
        "MyModuleWithParamsTuned.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 946
        },
        "id": "-o8r_sfCdrMy",
        "outputId": "82f789a7-8e7e-45c3-a53b-e533989dd64b"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/tvm/script/highlight.py:117: UserWarning: No module named 'black'\n",
            "To print formatted TVM script, please install the formatter 'Black':\n",
            "/usr/bin/python3 -m pip install \"black==22.3.0\" --upgrade --user\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<div class=\"highlight\" style=\"background: \"><pre style=\"line-height: 125%;\"><span></span><span style=\"color: #007979; font-style: italic\"># from tvm.script import ir as I</span>\n",
              "<span style=\"color: #007979; font-style: italic\"># from tvm.script import tir as T</span>\n",
              "<span style=\"color: #007979; font-style: italic\"># from tvm.script import relax as R</span>\n",
              "\n",
              "<span style=\"color: #AA22FF\">@I</span><span style=\"color: #AA22FF; font-weight: bold\">.</span>ir_module\n",
              "<span style=\"color: #008000; font-weight: bold\">class</span> <span style=\"color: #0000FF; font-weight: bold\">Module</span>:\n",
              "    <span style=\"color: #AA22FF\">@T</span><span style=\"color: #AA22FF; font-weight: bold\">.</span>prim_func\n",
              "    <span style=\"color: #008000; font-weight: bold\">def</span> <span style=\"color: #0000FF\">linear0</span>(X: T<span style=\"color: #AA22FF; font-weight: bold\">.</span>Buffer((<span style=\"color: #008000\">1</span>, <span style=\"color: #008000\">784</span>), <span style=\"color: #BA2121\">&quot;float32&quot;</span>), W: T<span style=\"color: #AA22FF; font-weight: bold\">.</span>Buffer((<span style=\"color: #008000\">128</span>, <span style=\"color: #008000\">784</span>), <span style=\"color: #BA2121\">&quot;float32&quot;</span>), B: T<span style=\"color: #AA22FF; font-weight: bold\">.</span>Buffer((<span style=\"color: #008000\">128</span>,), <span style=\"color: #BA2121\">&quot;float32&quot;</span>), Z: T<span style=\"color: #AA22FF; font-weight: bold\">.</span>Buffer((<span style=\"color: #008000\">1</span>, <span style=\"color: #008000\">128</span>), <span style=\"color: #BA2121\">&quot;float32&quot;</span>)):\n",
              "        T<span style=\"color: #AA22FF; font-weight: bold\">.</span>func_attr({<span style=\"color: #BA2121\">&quot;global_symbol&quot;</span>: <span style=\"color: #BA2121\">&quot;linear0&quot;</span>, <span style=\"color: #BA2121\">&quot;tir.noalias&quot;</span>: T<span style=\"color: #AA22FF; font-weight: bold\">.</span>bool(<span style=\"color: #008000; font-weight: bold\">True</span>)})\n",
              "        <span style=\"color: #007979; font-style: italic\"># with T.block(&quot;root&quot;):</span>\n",
              "        Y <span style=\"color: #AA22FF; font-weight: bold\">=</span> T<span style=\"color: #AA22FF; font-weight: bold\">.</span>alloc_buffer((<span style=\"color: #008000\">1</span>, <span style=\"color: #008000\">128</span>))\n",
              "        <span style=\"color: #008000; font-weight: bold\">for</span> i_0_j_0_i_1_j_1_fused <span style=\"color: #008000; font-weight: bold\">in</span> T<span style=\"color: #AA22FF; font-weight: bold\">.</span>parallel(<span style=\"color: #008000\">16</span>, annotations<span style=\"color: #AA22FF; font-weight: bold\">=</span>{<span style=\"color: #BA2121\">&quot;pragma_auto_unroll_max_step&quot;</span>: <span style=\"color: #008000\">512</span>, <span style=\"color: #BA2121\">&quot;pragma_unroll_explicit&quot;</span>: <span style=\"color: #008000\">1</span>}):\n",
              "            <span style=\"color: #008000; font-weight: bold\">for</span> i_2_init, j_2_init, i_3_init, j_3_init <span style=\"color: #008000; font-weight: bold\">in</span> T<span style=\"color: #AA22FF; font-weight: bold\">.</span>grid(<span style=\"color: #008000\">1</span>, <span style=\"color: #008000\">8</span>, <span style=\"color: #008000\">1</span>, <span style=\"color: #008000\">1</span>):\n",
              "                <span style=\"color: #008000; font-weight: bold\">with</span> T<span style=\"color: #AA22FF; font-weight: bold\">.</span>block(<span style=\"color: #BA2121\">&quot;Y_init&quot;</span>):\n",
              "                    vi <span style=\"color: #AA22FF; font-weight: bold\">=</span> T<span style=\"color: #AA22FF; font-weight: bold\">.</span>axis<span style=\"color: #AA22FF; font-weight: bold\">.</span>spatial(<span style=\"color: #008000\">1</span>, i_2_init <span style=\"color: #AA22FF; font-weight: bold\">+</span> i_3_init)\n",
              "                    vj <span style=\"color: #AA22FF; font-weight: bold\">=</span> T<span style=\"color: #AA22FF; font-weight: bold\">.</span>axis<span style=\"color: #AA22FF; font-weight: bold\">.</span>spatial(<span style=\"color: #008000\">128</span>, i_0_j_0_i_1_j_1_fused <span style=\"color: #AA22FF; font-weight: bold\">*</span> <span style=\"color: #008000\">8</span> <span style=\"color: #AA22FF; font-weight: bold\">+</span> j_2_init <span style=\"color: #AA22FF; font-weight: bold\">+</span> j_3_init)\n",
              "                    T<span style=\"color: #AA22FF; font-weight: bold\">.</span>reads()\n",
              "                    T<span style=\"color: #AA22FF; font-weight: bold\">.</span>writes(Y[vi, vj])\n",
              "                    T<span style=\"color: #AA22FF; font-weight: bold\">.</span>block_attr({<span style=\"color: #BA2121\">&quot;meta_schedule.tiling_structure&quot;</span>: <span style=\"color: #BA2121\">&quot;SSRSRS&quot;</span>})\n",
              "                    Y[vi, vj] <span style=\"color: #AA22FF; font-weight: bold\">=</span> T<span style=\"color: #AA22FF; font-weight: bold\">.</span>float32(<span style=\"color: #008000\">0</span>)\n",
              "            <span style=\"color: #008000; font-weight: bold\">for</span> k_0, i_2, j_2, k_1, i_3, j_3 <span style=\"color: #008000; font-weight: bold\">in</span> T<span style=\"color: #AA22FF; font-weight: bold\">.</span>grid(<span style=\"color: #008000\">112</span>, <span style=\"color: #008000\">1</span>, <span style=\"color: #008000\">8</span>, <span style=\"color: #008000\">7</span>, <span style=\"color: #008000\">1</span>, <span style=\"color: #008000\">1</span>):\n",
              "                <span style=\"color: #008000; font-weight: bold\">with</span> T<span style=\"color: #AA22FF; font-weight: bold\">.</span>block(<span style=\"color: #BA2121\">&quot;Y_update&quot;</span>):\n",
              "                    vi <span style=\"color: #AA22FF; font-weight: bold\">=</span> T<span style=\"color: #AA22FF; font-weight: bold\">.</span>axis<span style=\"color: #AA22FF; font-weight: bold\">.</span>spatial(<span style=\"color: #008000\">1</span>, i_2 <span style=\"color: #AA22FF; font-weight: bold\">+</span> i_3)\n",
              "                    vj <span style=\"color: #AA22FF; font-weight: bold\">=</span> T<span style=\"color: #AA22FF; font-weight: bold\">.</span>axis<span style=\"color: #AA22FF; font-weight: bold\">.</span>spatial(<span style=\"color: #008000\">128</span>, i_0_j_0_i_1_j_1_fused <span style=\"color: #AA22FF; font-weight: bold\">*</span> <span style=\"color: #008000\">8</span> <span style=\"color: #AA22FF; font-weight: bold\">+</span> j_2 <span style=\"color: #AA22FF; font-weight: bold\">+</span> j_3)\n",
              "                    vk <span style=\"color: #AA22FF; font-weight: bold\">=</span> T<span style=\"color: #AA22FF; font-weight: bold\">.</span>axis<span style=\"color: #AA22FF; font-weight: bold\">.</span>reduce(<span style=\"color: #008000\">784</span>, k_0 <span style=\"color: #AA22FF; font-weight: bold\">*</span> <span style=\"color: #008000\">7</span> <span style=\"color: #AA22FF; font-weight: bold\">+</span> k_1)\n",
              "                    T<span style=\"color: #AA22FF; font-weight: bold\">.</span>reads(Y[vi, vj], X[vi, vk], W[vj, vk])\n",
              "                    T<span style=\"color: #AA22FF; font-weight: bold\">.</span>writes(Y[vi, vj])\n",
              "                    T<span style=\"color: #AA22FF; font-weight: bold\">.</span>block_attr({<span style=\"color: #BA2121\">&quot;meta_schedule.tiling_structure&quot;</span>: <span style=\"color: #BA2121\">&quot;SSRSRS&quot;</span>})\n",
              "                    Y[vi, vj] <span style=\"color: #AA22FF; font-weight: bold\">=</span> Y[vi, vj] <span style=\"color: #AA22FF; font-weight: bold\">+</span> X[vi, vk] <span style=\"color: #AA22FF; font-weight: bold\">*</span> W[vj, vk]\n",
              "            <span style=\"color: #008000; font-weight: bold\">for</span> ax0 <span style=\"color: #008000; font-weight: bold\">in</span> range(<span style=\"color: #008000\">1</span>):\n",
              "                <span style=\"color: #008000; font-weight: bold\">for</span> ax1_fused <span style=\"color: #008000; font-weight: bold\">in</span> T<span style=\"color: #AA22FF; font-weight: bold\">.</span>vectorized(<span style=\"color: #008000\">8</span>):\n",
              "                    <span style=\"color: #008000; font-weight: bold\">with</span> T<span style=\"color: #AA22FF; font-weight: bold\">.</span>block(<span style=\"color: #BA2121\">&quot;Z&quot;</span>):\n",
              "                        vi <span style=\"color: #AA22FF; font-weight: bold\">=</span> T<span style=\"color: #AA22FF; font-weight: bold\">.</span>axis<span style=\"color: #AA22FF; font-weight: bold\">.</span>spatial(<span style=\"color: #008000\">1</span>, ax0)\n",
              "                        vj <span style=\"color: #AA22FF; font-weight: bold\">=</span> T<span style=\"color: #AA22FF; font-weight: bold\">.</span>axis<span style=\"color: #AA22FF; font-weight: bold\">.</span>spatial(<span style=\"color: #008000\">128</span>, i_0_j_0_i_1_j_1_fused <span style=\"color: #AA22FF; font-weight: bold\">*</span> <span style=\"color: #008000\">8</span> <span style=\"color: #AA22FF; font-weight: bold\">+</span> ax1_fused)\n",
              "                        T<span style=\"color: #AA22FF; font-weight: bold\">.</span>reads(Y[vi, vj], B[vj])\n",
              "                        T<span style=\"color: #AA22FF; font-weight: bold\">.</span>writes(Z[vi, vj])\n",
              "                        Z[vi, vj] <span style=\"color: #AA22FF; font-weight: bold\">=</span> Y[vi, vj] <span style=\"color: #AA22FF; font-weight: bold\">+</span> B[vj]\n",
              "\n",
              "    <span style=\"color: #AA22FF\">@R</span><span style=\"color: #AA22FF; font-weight: bold\">.</span>function\n",
              "    <span style=\"color: #008000; font-weight: bold\">def</span> <span style=\"color: #0000FF\">main</span>(x: R<span style=\"color: #AA22FF; font-weight: bold\">.</span>Tensor((<span style=\"color: #008000\">1</span>, <span style=\"color: #008000\">784</span>), dtype<span style=\"color: #AA22FF; font-weight: bold\">=</span><span style=\"color: #BA2121\">&quot;float32&quot;</span>)) <span style=\"color: #AA22FF; font-weight: bold\">-&gt;</span> R<span style=\"color: #AA22FF; font-weight: bold\">.</span>Tensor((<span style=\"color: #008000\">1</span>, <span style=\"color: #008000\">10</span>), dtype<span style=\"color: #AA22FF; font-weight: bold\">=</span><span style=\"color: #BA2121\">&quot;float32&quot;</span>):\n",
              "        <span style=\"color: #008000; font-weight: bold\">with</span> R<span style=\"color: #AA22FF; font-weight: bold\">.</span>dataflow():\n",
              "            lv0 <span style=\"color: #AA22FF; font-weight: bold\">=</span> R<span style=\"color: #AA22FF; font-weight: bold\">.</span>call_dps_packed(<span style=\"color: #BA2121\">&quot;linear0&quot;</span>, (x, metadata[<span style=\"color: #BA2121\">&quot;relax.expr.Constant&quot;</span>][<span style=\"color: #008000\">0</span>], metadata[<span style=\"color: #BA2121\">&quot;relax.expr.Constant&quot;</span>][<span style=\"color: #008000\">1</span>]), out_sinfo<span style=\"color: #AA22FF; font-weight: bold\">=</span>R<span style=\"color: #AA22FF; font-weight: bold\">.</span>Tensor((<span style=\"color: #008000\">1</span>, <span style=\"color: #008000\">128</span>), dtype<span style=\"color: #AA22FF; font-weight: bold\">=</span><span style=\"color: #BA2121\">&quot;float32&quot;</span>))\n",
              "            lv1 <span style=\"color: #AA22FF; font-weight: bold\">=</span> R<span style=\"color: #AA22FF; font-weight: bold\">.</span>call_dps_packed(<span style=\"color: #BA2121\">&quot;env.relu&quot;</span>, (lv0,), out_sinfo<span style=\"color: #AA22FF; font-weight: bold\">=</span>R<span style=\"color: #AA22FF; font-weight: bold\">.</span>Tensor((<span style=\"color: #008000\">1</span>, <span style=\"color: #008000\">128</span>), dtype<span style=\"color: #AA22FF; font-weight: bold\">=</span><span style=\"color: #BA2121\">&quot;float32&quot;</span>))\n",
              "            out <span style=\"color: #AA22FF; font-weight: bold\">=</span> R<span style=\"color: #AA22FF; font-weight: bold\">.</span>call_dps_packed(<span style=\"color: #BA2121\">&quot;env.linear&quot;</span>, (lv1, metadata[<span style=\"color: #BA2121\">&quot;relax.expr.Constant&quot;</span>][<span style=\"color: #008000\">2</span>], metadata[<span style=\"color: #BA2121\">&quot;relax.expr.Constant&quot;</span>][<span style=\"color: #008000\">3</span>]), out_sinfo<span style=\"color: #AA22FF; font-weight: bold\">=</span>R<span style=\"color: #AA22FF; font-weight: bold\">.</span>Tensor((<span style=\"color: #008000\">1</span>, <span style=\"color: #008000\">10</span>), dtype<span style=\"color: #AA22FF; font-weight: bold\">=</span><span style=\"color: #BA2121\">&quot;float32&quot;</span>))\n",
              "            R<span style=\"color: #AA22FF; font-weight: bold\">.</span>output(out)\n",
              "        <span style=\"color: #008000; font-weight: bold\">return</span> out\n",
              "\n",
              "<span style=\"color: #007979; font-style: italic\"># Metadata omitted. Use show_meta=True in script() method to show it.</span>\n",
              "</pre></div>\n"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# build\n",
        "ex = relax.build(MyModuleWithParamsTuned, target='llvm')\n",
        "vm = relax.VirtualMachine(ex, tvm.cpu())\n",
        "\n",
        "# run\n",
        "nd_res = vm[\"main\"](data_nd)\n",
        "\n",
        "# result\n",
        "pred_kind = np.argmax(nd_res.numpy(), axis=1)\n",
        "print(\"my module tuned:\", class_names[pred_kind[0]])\n",
        "\n",
        "# evaluate runtime (average on 100 trails)\n",
        "ftimer = vm.module.time_evaluator(\"main\", tvm.cpu(), number=100)\n",
        "print(\"my module tuned time cost\", ftimer(data_nd).mean * 1000, \"ms\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_GBh0Neke159",
        "outputId": "a527324c-e9e0-43f5-d173-8401f2bfa505"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "my module tuned: Sneaker\n",
            "my module tuned time cost 0.10814829000000001 ms\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Summary\n",
        "\n",
        "- by tuning the linear tensor ir primitive function, the runtime performance sees a 3x speedup.\n",
        "\n",
        "- auto opt comes handy when tuning the performance."
      ],
      "metadata": {
        "id": "0snwtauafk7-"
      }
    }
  ]
}